{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression\n",
    "- 设置不同threshold找motif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcXe', 'abcXes', 'abcXesd', 'bcXe', 'bcXes', 'bcXesd', 'bcXesdXXl', 'cXes', 'cXesd', 'cXesdXXl', 'cXesdXXlg', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXl', 'sdXXlg', 'sdXXlgf', 'dXXl', 'dXXlg', 'dXXlgf']\n",
      "['abcXe', 'abcXes', 'abcXesd', 'bcXe', 'bcXes', 'bcXesd', 'bcXesdXXl', 'cXes', 'cXesd', 'cXesdXXl', 'cXesdXXlg', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXl', 'sdXXlg', 'sdXXlgf', 'dXXl', 'dXXlg', 'dXXlgf']\n"
     ]
    }
   ],
   "source": [
    "def get_substring_indices(input_string):\n",
    "    # 输入一个字符串，输出一个列表，列表中的元素为该字符串的子串的index区间\n",
    "    indices = []\n",
    "    length = len(input_string)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(i+4,  min(i+10, length+1)):\n",
    "            indices.append([i, j])\n",
    "    \n",
    "    return indices\n",
    "\n",
    "\n",
    "def filterSubstring(grad:list, alpha:float, indexLs:list, seq:str):\n",
    "    alpha_grad = [v if v>=alpha else 0 for v in grad]\n",
    "    finalLs = []\n",
    "    for i in indexLs:\n",
    "        subGrad = alpha_grad[i[0]:i[1]]\n",
    "        flag = subGrad.count(0)\n",
    "        if flag <= int((i[1]-i[0])/2):\n",
    "            subSeq = list(seq[i[0]:i[1]])\n",
    "            for j in range(len(subSeq)):\n",
    "                if subGrad[j] == 0:\n",
    "                    subSeq[j] = 'X'\n",
    "            if subSeq[0]!= 'X' and subSeq[-1]!= 'X':\n",
    "                finalLs.append(''.join(subSeq))\n",
    "\n",
    "\n",
    "    return finalLs\n",
    "\n",
    "\n",
    "def filterSubstring2(grad:list, alpha:float, indexLs:list, seq:str):\n",
    "    alpha_grad = [v if v>=alpha else 0 for v in grad]\n",
    "    finalLs = []\n",
    "    for i in indexLs:\n",
    "        subGrad = alpha_grad[i[0]:i[1]]\n",
    "        flag = subGrad.count(0)\n",
    "        if flag <= int((i[1]-i[0])/2):\n",
    "            subSeq = list(seq[i[0]:i[1]])\n",
    "            for j in range(len(subSeq)):\n",
    "                if subGrad[j] == 0:\n",
    "                    subSeq[j] = 'X'\n",
    "            if subSeq[0]!= 'X' and subSeq[-1]!= 'X':\n",
    "                finalLs.append(''.join(subSeq))\n",
    "\n",
    "\n",
    "    return finalLs\n",
    "\n",
    "\n",
    "def find_motif(input_string,grad,alpha):\n",
    "    result = get_substring_indices(input_string)\n",
    "    ls = filterSubstring(grad,alpha=alpha, indexLs = result, seq=input_string)\n",
    "\n",
    "    return ls\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "input_string = \"abcdesdkjlgf\"\n",
    "grad = [.4,.6,.4,0,.4,.6,.4,0,0,.4,.6,.4,]\n",
    "result = get_substring_indices(input_string)\n",
    "ls = filterSubstring(grad,alpha = 0.4, indexLs = result, seq=input_string)\n",
    "print(ls)\n",
    "ls1 = find_motif(input_string=input_string,grad = grad,alpha=0.4)\n",
    "print(ls1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 添加NBT attention模型\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "# 下面这几行是为了调用NBT att模型\n",
    "from keras.models import load_model\n",
    "from numpy import loadtxt, savetxt\n",
    "import re\n",
    "\n",
    "from Attention import Attention_layer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://pepcalc.com/ppc.php\"\n",
    "\n",
    "mydata = json.loads(\n",
    "    '{\"hideInputFields\": \"no\",\"nTerm\": \"(NH2-)\",\"cTerm\": \"(-COOH)\",\"aaCode\": 0,\"disulphideBonds\": \"\",\"sequence\": \"\"}')\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Content-Length': '<calculated when request is sent>'\n",
    "}\n",
    "\n",
    "\n",
    "mydict = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "myInvDict = dict([val, key] for key, val in mydict.items())\n",
    "sigmoid = torch.sigmoid\n",
    "\n",
    "\n",
    "NBTdict = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_MIC = math.log10(8192)\n",
    "max_mic_buffer = 0.1\n",
    "My_MAX_MIC = math.log10(600)\n",
    "\n",
    "\n",
    "def CosineSimilarity(tensor_1, tensor_2):\n",
    "    tensor_1 = tensor_1.squeeze()\n",
    "    tensor_2 = tensor_2.squeeze()\n",
    "\n",
    "    normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)\n",
    "    normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)\n",
    "    return (normalized_tensor_1 * normalized_tensor_2).sum()\n",
    "    \n",
    "def seq2num(seq):\n",
    "    \n",
    "    seqlist = list(seq)\n",
    "\n",
    "    length = len(seq)\n",
    "    result = re.findall(r'[BJOUXZ]',seq)\n",
    "\n",
    "    if result:\n",
    "        return \n",
    "\n",
    "    # 否则正常返回\n",
    "    else:\n",
    "        numlist = [NBTdict[char.upper()] for char in seqlist]\n",
    "        \n",
    "        zeroPad = [0 for i in range(300-length)]\n",
    "        zeroPad.extend(numlist)\n",
    "        zeroPad = np.array(zeroPad)\n",
    "        \n",
    "        return zeroPad\n",
    "\n",
    "\n",
    "def dataProcessPipeline(seq):\n",
    "    # 本函数先把序列转化为0-19组成的序列，然后onehot变化，再padding\n",
    "    # 同时返回padding后的序列以及mask\n",
    "    #print('ori seq',seq)\n",
    "    testest = seq\n",
    "    num_seq = [mydict[character.upper()] for character in seq]\n",
    "\n",
    "    seq = np.array(num_seq,dtype=int)\n",
    "    len = seq.shape[0]\n",
    "    torch_seq = torch.tensor(seq)\n",
    "\n",
    "    if torch.sum(torch_seq[torch_seq<0])!=0:\n",
    "        print(torch_seq[torch_seq<0])\n",
    "        print('wrong seq:',seq)\n",
    "        print(testest)\n",
    "\n",
    "    onehotSeq = torch.nn.functional.one_hot(torch_seq,num_classes=20)\n",
    "    pad = torch.nn.ZeroPad2d(padding=(0,0,0,100-len))\n",
    "    mask = np.zeros(100,dtype = int)\n",
    "    mask[len:]=1\n",
    "    mask = torch.tensor(mask)\n",
    "    pad_seq = pad(onehotSeq) \n",
    "    \n",
    "    \n",
    "    return pad_seq,mask\n",
    "\n",
    "\n",
    "def num2onehot(array2d):\n",
    "    result = torch.zeros_like(array2d)\n",
    "    index = torch.argmax(array2d,dim = -1)\n",
    "    for i in range(index.shape[0]):\n",
    "        result[i,index[i]] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "\n",
    "        df = pd.read_csv(data_path,header=0)\n",
    "        self.df = df\n",
    "        self.seqs = list(self.df['sequence'])\n",
    "\n",
    "        #print(self.seqs.shape)\n",
    "        self.values = self.df['value']\n",
    "        # 数据集的单边阈值设置\n",
    "        self.values[self.values>MAX_MIC] = MAX_MIC\n",
    "        self.values = list(self.values)\n",
    "        #print(self.labels.shape)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "        label = self.values[idex]\n",
    "\n",
    "\n",
    "        return num_seq, mask, label, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "        self.df = pd.read_csv(data_path,header=0)\n",
    "        self.seqs = self.df['Sequence']\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "\n",
    "        return num_seq, mask, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "     def __init__(self, len, d_model=20, dropout=0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(len, d_model)\n",
    "        position = torch.arange(0, len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                                * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "     def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        #x = x + self.pe[:,:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "pe = PositionalEncoding(len=100,d_model = 20)\n",
    "\n",
    "\n",
    "class AttentionNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self,batch_size=128,embedding_size=20,num_tokens=100,num_classes=1,num_heads=4):\n",
    "        super(AttentionNetwork,self).__init__()\n",
    "        self.pe = PositionalEncoding(len=num_tokens,d_model = embedding_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        # self.hidden1 = 20\n",
    "        self.hidden1 = 20\n",
    "        self.hidden2 = 60\n",
    "        self.hidden3 = 20\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # self.hidden2 = 100\n",
    "        # self.hidden3 = 50\n",
    "        # self.hidden4 = 20\n",
    "        # self.dropout = 0.2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.LN = nn.LayerNorm(normalized_shape = self.hidden1)\n",
    "        self.fc1 = nn.Linear(self.embedding_size,self.hidden1)\n",
    "\n",
    "        # self.qfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.kfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.vfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "\n",
    "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1,num_heads = self.num_heads,batch_first=1,dropout=self.dropout)\n",
    "        # 我这里先不用maxpool了\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(self.hidden1*self.num_tokens,self.hidden2)\n",
    "        self.fc3 = nn.Linear(self.hidden2,self.hidden3)\n",
    "        self.new_fc4 = nn.Linear(self.hidden3,self.num_classes)\n",
    "        # self.fc4 = nn.Linear(self.hidden3,self.hidden4)\n",
    "        # self.fc5 = nn.Linear(self.hidden4,self.num_classes)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.softmax = nn.functional.softmax\n",
    "\n",
    "\n",
    "    #这里的X当作对象 有 embedding 和 mask\n",
    "    def forward(self,x,mask):\n",
    "        x = self.pe(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "\n",
    "        mask = mask.to(torch.bool)\n",
    "        x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "\n",
    "\n",
    "        # x = self.LN(x)\n",
    "        # [N 100 20]\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(type(x),x.size)\n",
    "        # x = torch.tensor(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.new_fc4(x)\n",
    "\n",
    "\n",
    "        #return x, w1, w2, w3, w4\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : ['LWWXK', 'LWWXKXXW', 'WWXK', 'WWXKXXW', 'WWXKXXWK', 'WXKXXW', 'WXKXXWK', 'KXXW', 'KXXWK', 'KXXWKXXI', 'WKXXI', 'WKXXIXK', 'KXXI', 'KXXIXK', 'KXXIXKXM', 'IXKXM', 'IXKXMI', 'IXKXMIR', 'IXKXMIRV', 'KXMI', 'KXMIR', 'KXMIRV', 'KXMIRVI', 'MIRV', 'MIRVI', 'IRVI', 'RVIXXXXI']\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : ['LWWXK', 'LWWXKXXW', 'WWXK', 'WWXKXXW', 'WXKXXW', 'KXXW', 'KXMI', 'KXMIR']\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : ['LWWXK', 'LWWXKXXW', 'WWXK', 'WWXKXXW', 'WXKXXW', 'KXXW']\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : ['LWWXXXXW']\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI : []\n",
      "0.9999999999999997\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : ['KWLG', 'KWLGXF', 'KWLGXFG', 'KWLGXFGK', 'WLGXF', 'WLGXFG', 'WLGXFGK', 'LGXF', 'LGXFG', 'LGXFGK', 'LGXFGKXR', 'GXFG', 'GXFGK', 'GXFGKXR', 'GXFGKXRK', 'FGKXR', 'FGKXRK', 'FGKXRKI', 'FGKXRKIA', 'GKXR', 'GKXRK', 'GKXRKI', 'GKXRKIA', 'GKXRKIAI', 'KXRK', 'KXRKI', 'KXRKIA', 'KXRKIAI', 'KXRKIAIR', 'RKIA', 'RKIAI', 'RKIAIR', 'RKIAIRXR', 'KIAI', 'KIAIR', 'KIAIRXR', 'KIAIRXRL', 'IAIR', 'IAIRXR', 'IAIRXRL', 'IAIRXRLK', 'AIRXR', 'AIRXRL', 'AIRXRLK', 'IRXR', 'IRXRL', 'IRXRLK', 'IRXRLKXK', 'RXRL', 'RXRLK', 'RXRLKXK', 'RXRLKXKK', 'RLKXK', 'RLKXKK', 'RLKXKKA', 'RLKXKKAF', 'LKXK', 'LKXKK', 'LKXKKA', 'LKXKKAF', 'KXKK', 'KXKKA', 'KXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : ['KWLG', 'KWLGXF', 'KWLGXFXK', 'WLGXF', 'WLGXFXK', 'LGXF', 'LGXFXK', 'LGXFXKXR', 'GXFXK', 'GXFXKXR', 'GXFXKXRK', 'FXKXR', 'FXKXRK', 'FXKXRKI', 'FXKXRKIA', 'KXRK', 'KXRKI', 'KXRKIA', 'KXRKIAI', 'KXRKIAIR', 'RKIA', 'RKIAI', 'RKIAIR', 'KIAI', 'KIAIR', 'IAIR', 'IAIRXXXK', 'AIRXXXK', 'IRXXXK', 'IRXXXKXK', 'RXXXKXKK', 'KXKK', 'KXKKA', 'KXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : ['KWXG', 'KWXGXF', 'WXGXF', 'GXFXXXRK', 'FXXXRK', 'RKXXI', 'RKXXIR', 'KXXI', 'KXXIR']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : ['WXGXF', 'GXFXXXRK', 'FXXXRK', 'RKXXI', 'RKXXIR', 'KXXI', 'KXXIR']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "WWRLWKTLLKAPKKLTGLRRW\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRL', 'WWRLW', 'WWRLWK', 'WWRLWKXL', 'WRLW', 'WRLWK', 'WRLWKXL', 'WRLWKXLL', 'RLWK', 'RLWKXL', 'RLWKXLL', 'RLWKXLLK', 'LWKXL', 'LWKXLL', 'LWKXLLK', 'LWKXLLKA', 'WKXL', 'WKXLL', 'WKXLLK', 'WKXLLKA', 'KXLL', 'KXLLK', 'KXLLKA', 'KXLLKAXK', 'LLKA', 'LLKAXK', 'LLKAXKK', 'LLKAXKKL', 'LKAXK', 'LKAXKK', 'LKAXKKL', 'KAXK', 'KAXKK', 'KAXKKL', 'KAXKKLXG', 'AXKK', 'AXKKL', 'AXKKLXG', 'AXKKLXGL', 'KKLXG', 'KKLXGL', 'KKLXGLR', 'KKLXGLRR', 'KLXG', 'KLXGL', 'KLXGLR', 'KLXGLRR', 'KLXGLRRW', 'LXGL', 'LXGLR', 'LXGLRR', 'LXGLRRW', 'GLRR', 'GLRRW', 'LRRW']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRL', 'WWRLW', 'WWRLWK', 'WWRLWKXL', 'WRLW', 'WRLWK', 'WRLWKXL', 'WRLWKXLL', 'RLWK', 'RLWKXL', 'RLWKXLL', 'RLWKXLLK', 'LWKXL', 'LWKXLL', 'LWKXLLK', 'WKXL', 'WKXLL', 'WKXLLK', 'KXLL', 'KXLLK', 'KXLLKXXK', 'LLKXXK', 'LLKXXKK', 'LLKXXKKL', 'LKXXK', 'LKXXKK', 'LKXXKKL', 'KXXK', 'KXXKK', 'KXXKKL', 'KXXKKLXG', 'KKLXG', 'KKLXGL', 'KKLXGLR', 'KKLXGLRR', 'KLXG', 'KLXGL', 'KLXGLR', 'KLXGLRR', 'KLXGLRRW', 'LXGL', 'LXGLR', 'LXGLRR', 'LXGLRRW', 'GLRR', 'GLRRW', 'LRRW']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRXXK', 'WRXXK', 'WRXXKXXL', 'RXXK', 'RXXKXXLK', 'KXXL', 'KXXLK', 'KXXLKXXK', 'LKXXK', 'LKXXKK', 'KXXK', 'KXXKK', 'KKXXXL', 'KKXXXLR', 'KKXXXLRR', 'KXXXLR', 'KXXXLRR', 'KXXXLRRW', 'LRRW']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRXXK', 'WRXXK', 'RXXK', 'KXXK', 'KXXKK', 'KKXXXL', 'LXXW']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRXXK', 'WRXXK', 'RXXK', 'KXXK', 'KXXKK', 'KKXXXL']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['WWRXXK', 'WRXXK', 'RXXK', 'KXXK', 'KXXKK', 'KKXXXL']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['KXXK', 'KXXKK']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : ['KXXK', 'KXXKK']\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : []\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : []\n",
      "1.0000000000000002\n",
      "WWRLWKTLLKAPKKLTGLRRW : []\n",
      "1.0000000000000002\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "RKLKKLRWRAGMMYKYVKLK\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXKK', 'KXKKL', 'KXKKLR', 'KXKKLRW', 'KXKKLRWR', 'KKLR', 'KKLRW', 'KKLRWR', 'KKLRWRXG', 'KLRW', 'KLRWR', 'KLRWRXG', 'KLRWRXGM', 'LRWR', 'LRWRXG', 'LRWRXGM', 'LRWRXGMM', 'RWRXG', 'RWRXGM', 'RWRXGMM', 'RWRXGMMY', 'WRXG', 'WRXGM', 'WRXGMM', 'WRXGMMY', 'WRXGMMYK', 'RXGM', 'RXGMM', 'RXGMMY', 'RXGMMYK', 'RXGMMYKY', 'GMMY', 'GMMYK', 'GMMYKY', 'GMMYKYV', 'GMMYKYVK', 'MMYK', 'MMYKY', 'MMYKYV', 'MMYKYVK', 'MMYKYVKL', 'MYKY', 'MYKYV', 'MYKYVK', 'MYKYVKL', 'MYKYVKLK', 'YKYV', 'YKYVK', 'YKYVKL', 'YKYVKLK', 'KYVK', 'KYVKL', 'KYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXKK', 'KXKKXR', 'KXKKXRW', 'KXKKXRWR', 'KKXR', 'KKXRW', 'KKXRWR', 'KXRW', 'KXRWR', 'KXRWRXXM', 'RWRXXM', 'RWRXXMM', 'RWRXXMMY', 'WRXXM', 'WRXXMM', 'WRXXMMY', 'WRXXMMYK', 'RXXM', 'RXXMM', 'RXXMMY', 'RXXMMYK', 'RXXMMYKY', 'MMYK', 'MMYKY', 'MMYKYV', 'MMYKYVK', 'MMYKYVKL', 'MYKY', 'MYKYV', 'MYKYVK', 'MYKYVKL', 'MYKYVKLK', 'YKYV', 'YKYVK', 'YKYVKL', 'YKYVKLK', 'KYVK', 'KYVKL', 'KYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXKK', 'KXKKXR', 'KXKKXRW', 'KXKKXRWR', 'KKXR', 'KKXRW', 'KKXRWR', 'KXRW', 'KXRWR', 'KXRWRXXM', 'RWRXXM', 'RWRXXMM', 'RWRXXMMY', 'WRXXM', 'WRXXMM', 'WRXXMMY', 'WRXXMMYK', 'RXXM', 'RXXMM', 'RXXMMY', 'RXXMMYK', 'RXXMMYKY', 'MMYK', 'MMYKY', 'MMYKYXK', 'MMYKYXKL', 'MYKY', 'MYKYXK', 'MYKYXKL', 'MYKYXKLK', 'YKYXK', 'YKYXKL', 'YKYXKLK', 'KYXK', 'KYXKL', 'KYXKLK', 'YXKL', 'YXKLK']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXKK', 'KXKKXR', 'KXKKXRW', 'KKXR', 'KKXRW', 'KXRW', 'KXRWXXXM', 'RWXXXM', 'RWXXXMM', 'RWXXXMMY', 'WXXXMM', 'WXXXMMY', 'WXXXMMYK', 'MMYK', 'MMYKY', 'MMYKYXK', 'MMYKYXKL', 'MYKY', 'MYKYXK', 'MYKYXKL', 'MYKYXKLK', 'YKYXK', 'YKYXKL', 'YKYXKLK', 'KYXK', 'KYXKL', 'KYXKLK', 'YXKL', 'YXKLK']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXXK', 'KXXW', 'WXXXMM', 'WXXXMMY', 'WXXXMMYK', 'MMYK', 'MMYKY', 'MMYKYXK', 'MMYKYXKL', 'MYKY', 'MYKYXK', 'MYKYXKL', 'YKYXK', 'YKYXKL', 'KYXK', 'KYXKL', 'YXKL']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['KXXW', 'MXYXY', 'MXYXYXXL', 'YXYXXL', 'YXXL']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['MXYXY', 'MXYXYXXL', 'YXYXXL', 'YXXL']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : ['MXYXY', 'MXYXYXXL', 'YXYXXL', 'YXXL']\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : []\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : []\n",
      "0.9999999999999999\n",
      "RKLKKLRWRAGMMYKYVKLK : []\n",
      "0.9999999999999999\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MRFPWKHWWKKWKWWWKKKR\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXH', 'FXWXHW', 'WXHW', 'WXHWXXXW', 'HWXXXW', 'WXXW', 'WXXWW', 'WXXWWK', 'WXXWWKXK', 'WWKXK', 'WWKXKR', 'WKXK', 'WKXKR', 'KXKR']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXH', 'FXWXHW', 'WXHW', 'WXHWXXXW', 'HWXXXW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXH', 'FXWXHW', 'WXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXW', 'MRXXWXH', 'MRXXWXHW', 'RXXW', 'RXXWXH', 'RXXWXHW', 'WXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXW', 'MRXXWXH', 'MRXXWXHW', 'RXXW', 'RXXWXH', 'RXXWXHW', 'WXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXW', 'MRXXWXH', 'MRXXWXHW', 'RXXW', 'RXXWXH', 'RXXWXHW', 'WXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXW', 'MRXXWXH', 'MRXXWXHW', 'RXXW', 'RXXWXH', 'RXXWXHW', 'WXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXXXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXXXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : ['MRXXXXHW']\n",
      "1.0\n",
      "MRFPWKHWWKKWKWWWKKKR : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MKKARFWWWVAWKKLLRKKA\n",
      "MKKARFWWWVAWKKLLRKKA : ['MKKA', 'MKKAR', 'MKKARF', 'MKKARFW', 'MKKARFWW', 'KKAR', 'KKARF', 'KKARFW', 'KKARFWW', 'KARF', 'KARFW', 'KARFWW', 'ARFW', 'ARFWW', 'ARFWWXXA', 'RFWW', 'RFWWXXA', 'RFWWXXAW', 'FWWXXA', 'FWWXXAW', 'WWXXA', 'WWXXAW', 'WWXXAWXK', 'WXXA', 'WXXAW', 'WXXAWXK', 'WXXAWXKL', 'AWXK', 'AWXKL', 'AWXKLL', 'AWXKLLR', 'AWXKLLRK', 'WXKL', 'WXKLL', 'WXKLLR', 'WXKLLRK', 'WXKLLRKK', 'KLLR', 'KLLRK', 'KLLRKK', 'KLLRKKA', 'LLRK', 'LLRKK', 'LLRKKA', 'LRKK', 'LRKKA', 'RKKA']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'RFWWXXXW', 'FWWXXXW', 'WWXXXW', 'WXXL', 'WXXLL', 'WXXLLXXK', 'LLXXK', 'LLXXKA', 'LXXK', 'LXXKA']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'LLXXXA']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : ['MXXA', 'MXXAR', 'MXXARF', 'MXXARFW', 'MXXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'LLXXXA']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : ['MXXXRF', 'MXXXRFW']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : ['MXXXRF', 'MXXXRFW']\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : []\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : []\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : []\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : []\n",
      "0.9999999999999998\n",
      "MKKARFWWWVAWKKLLRKKA : []\n",
      "0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    # \n",
    "    'myAttention': '../../NewModel3_21_output1_Regression/myAttention/mean_0_changeTH_0_0/_AMP0.629_total0.543.pth',\n",
    "\n",
    "}\n",
    "\n",
    "test_model_list = model_list\n",
    "\n",
    "opt_seqls = [\n",
    "\n",
    "'LWWRKAKWKRKIAKRMIRVIGAAKI',                                                                                                                            \n",
    "'KWLGAFGKMRKIAIRLRLKRKKAF',                                                                                                                             \n",
    "'WWRLWKTLLKAPKKLTGLRRW',                                                                                                                             \n",
    "'RKLKKLRWRAGMMYKYVKLK',\n",
    "'MRFPWKHWWKKWKWWWKKKR',\n",
    "'MKKARFWWWVAWKKLLRKKA'\n",
    "]\n",
    "\n",
    "labels = [\n",
    "'myAttention9',\n",
    "'myAttention7',\n",
    "'CNN8',\n",
    "'myAttention9',\n",
    "'myAttention13',\n",
    "'myAttention9'\n",
    "]\n",
    "\n",
    "label_dict = {opt_seqls[i]:labels[i] for i in range(len(opt_seqls))}\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定之前保存的 JSON 文件名\n",
    "file_name = \"/home/user2/pj/AMP_2/attention_model/test_motif/score/seq_score_9_7_reg.json\"\n",
    "\n",
    "\n",
    "with open(file_name, \"r\") as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "score_seq_dict = {}\n",
    "for item in loaded_data:\n",
    "    seq = item['seq']\n",
    "    # print(seq)\n",
    "    score = np.array(item['score'])\n",
    "    score_seq_dict[seq] = score\n",
    "    # print(score.shape)\n",
    "    # draw_weight2(score,seq,'layer1')\n",
    "\n",
    "\n",
    "df_ls = []\n",
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "for seq in opt_seqls:\n",
    "    tseq = seq\n",
    "\n",
    "    # ModelNameList = ['CNN','Transformer','myAttention','RCNN']\n",
    "    ModelNameList = model_list.keys()\n",
    "\n",
    "    gradient = {}\n",
    "    \n",
    "\n",
    "    oriseq = tseq\n",
    "\n",
    "    # 在当前目录生成 该序列的csv 文件\n",
    "    df = pd.DataFrame(columns = ['Sequence','Length','label'])\n",
    "    items = [{'Sequence':oriseq,'Length':len(oriseq)}]\n",
    "    df = df.append(items,ignore_index = 1)\n",
    "    df.to_csv(oriseq+'.csv',index = False)\n",
    "\n",
    "\n",
    "    SeqPath = oriseq+'.csv'\n",
    "\n",
    "\n",
    "\n",
    "    testData1 = TrainDataset(data_path = r'../../myRegressionData/all_balance/mean/test.csv')\n",
    "    test_loader1 = DataLoader(dataset=testData1, batch_size=4,drop_last=True)\n",
    "\n",
    "\n",
    "    for modelName in ModelNameList:\n",
    "\n",
    "        # modelName = 'myAttention'  # to change\n",
    "        iternum = 0\n",
    "\n",
    "        testData = TestDataset(data_path = SeqPath)\n",
    "        test_loader = DataLoader(dataset=testData, batch_size=1)\n",
    "        attmodel = torch.load(model_list[modelName])\n",
    "\n",
    "\n",
    "        attmodel.cuda()\n",
    "        attmodel.zero_grad()\n",
    "\n",
    "        print(modelName,\"_V2:\")\n",
    "\n",
    "            \n",
    "        for data in test_loader: #序列优化 stratergy 1: 全局都用ensamble作为优化目标\n",
    "            resultList = []\n",
    "            # ensamble_values = []\n",
    "            resultSeq = [oriseq]\n",
    "            outMIC = []\n",
    "            # attmodel.zero_grad()\n",
    "            inputs,masks, seqs = data\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            masks = masks.float()\n",
    "            \n",
    "            # inputs = inputs.cuda()\n",
    "            # inputs.requires_grad = True\n",
    "            masks = masks.cuda()\n",
    "            print(seqs[0])\n",
    "\n",
    "            if modelName == 'RCNN':\n",
    "                attmodel.train()\n",
    "            else:\n",
    "                attmodel.eval()\n",
    "    \n",
    "            attmodel.zero_grad()\n",
    "            stdev_spread = 0.1\n",
    "            n_samples = 25\n",
    "            x = inputs[0].detach()\n",
    "            stdev = stdev_spread * (torch.max(x)-torch.min(x))\n",
    "            x = x.numpy() \n",
    "            total_grad = np.zeros_like(x)\n",
    "            for i in range(n_samples):\n",
    "\n",
    "                    # final.append(xx)\n",
    "                noise = np.random.normal(0,stdev,x.shape).astype(np.float32)\n",
    "                x_plus_noise = x + noise\n",
    "                \n",
    "                x_plus_noise = torch.from_numpy(x_plus_noise).cuda()\n",
    "                # x_plus_noise = x_plus_noise + 0.1\n",
    "                x_plus_noise[masks[0]==1] = 0\n",
    "                x_plus_noise = Variable(torch.unsqueeze(x_plus_noise,dim=0), requires_grad = True)\n",
    "                # final.append(x_plus_noise)\n",
    "                if i==0:\n",
    "                    x_plus_noise = Variable(inputs.cuda(), requires_grad = True)\n",
    "            \n",
    "                if modelName == 'lstm_att' or modelName == 'RCNN'or modelName == 'CNN' or modelName == 'Transformer':\n",
    "                    out = attmodel(x_plus_noise)\n",
    "                else:\n",
    "                    out = attmodel(x_plus_noise,masks)\n",
    "\n",
    "                out = out.cpu()\n",
    "                if 'RCNN' in modelName:\n",
    "                    out = out.unsqueeze(0)\n",
    "\n",
    "                conloss = -out\n",
    "\n",
    "                conloss.backward()\n",
    "                grad = x_plus_noise.grad\n",
    "                # if i==0:\n",
    "                #     print(grad)\n",
    "                colindex = masks[0]==1\n",
    "                grad[0][masks[0]==1] = 0\n",
    "                grad = grad[0].cpu().numpy()\n",
    "                \n",
    "                total_grad += grad\n",
    "\n",
    "\n",
    "            avg_grad = total_grad/n_samples\n",
    "            myIndex = [mydict[v] for v in seqs[0]]\n",
    "\n",
    "            mylen = 100-colindex.sum()\n",
    "            # print(mylen)\n",
    "            grad = avg_grad[:mylen]\n",
    "            # grad = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            mag = np.sum(abs(grad),axis=-1).tolist()\n",
    "\n",
    "            # print(np.sum(grad))\n",
    "\n",
    "            value = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            # print(value)\n",
    "            # max_grad = np.max(grad,axis=-1).tolist()\n",
    "            # # grad  =  [value[i]/max_grad[i] for i in range(len(grad))]\n",
    "            grad = [mag[k]*value[k] for k in range(len(value))]\n",
    "            # grad = list(np.exp(grad))\n",
    "\n",
    "            absGrad = np.sum(abs(np.array(grad)))\n",
    "            grad = [v/absGrad for v in grad]\n",
    "            # grad = [ v/sum(grad) for v in grad]\n",
    "            gradient[modelName] = grad\n",
    "    seq_dict = {'sequence': seq,'model':label_dict[seq]}\n",
    "    for k in range(11):\n",
    "        alpha = k/100\n",
    "        ls = find_motif(tseq,grad,alpha)\n",
    "        print(tseq,':',ls)\n",
    "        print(sum(abs(np.array(grad))))\n",
    "        seq_dict[alpha] = ls\n",
    "\n",
    "    df_ls.append(seq_dict)\n",
    "\n",
    "\n",
    "    # print(gradient)\n",
    "    # grad = gradient['myAttention']\n",
    "    # alpha = 0.05\n",
    "    # ls = find_motif(tseq,grad,alpha)\n",
    "    # print(tseq,':',ls)\n",
    "    # print(sum(abs(np.array(grad))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sequence          model  \\\n",
      "0  LWWRKAKWKRKIAKRMIRVIGAAKI   myAttention9   \n",
      "1   KWLGAFGKMRKIAIRLRLKRKKAF   myAttention7   \n",
      "2      WWRLWKTLLKAPKKLTGLRRW           CNN8   \n",
      "3       RKLKKLRWRAGMMYKYVKLK   myAttention9   \n",
      "4       MRFPWKHWWKKWKWWWKKKR  myAttention13   \n",
      "5       MKKARFWWWVAWKKLLRKKA   myAttention9   \n",
      "\n",
      "                                                 0.0  \\\n",
      "0  [LWWXK, LWWXKXXW, WWXK, WWXKXXW, WWXKXXWK, WXK...   \n",
      "1  [KWLG, KWLGXF, KWLGXFG, KWLGXFGK, WLGXF, WLGXF...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WWRLWKXL, WRLW, WRLWK, W...   \n",
      "3  [KXKK, KXKKL, KXKKLR, KXKKLRW, KXKKLRWR, KKLR,...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MKKA, MKKAR, MKKARF, MKKARFW, MKKARFWW, KKAR,...   \n",
      "\n",
      "                                                0.01  \\\n",
      "0  [LWWXK, LWWXKXXW, WWXK, WWXKXXW, WXKXXW, KXXW,...   \n",
      "1  [KWLG, KWLGXF, KWLGXFXK, WLGXF, WLGXFXK, LGXF,...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WWRLWKXL, WRLW, WRLWK, W...   \n",
      "3  [KXKK, KXKKXR, KXKKXRW, KXKKXRWR, KKXR, KKXRW,...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                0.02  \\\n",
      "0     [LWWXK, LWWXKXXW, WWXK, WWXKXXW, WXKXXW, KXXW]   \n",
      "1  [KWXG, KWXGXF, WXGXF, GXFXXXRK, FXXXRK, RKXXI,...   \n",
      "2  [WWRXXK, WRXXK, WRXXKXXL, RXXK, RXXKXXLK, KXXL...   \n",
      "3  [KXKK, KXKKXR, KXKKXRW, KXKKXRWR, KKXR, KKXRW,...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                0.03  \\\n",
      "0                                         [LWWXXXXW]   \n",
      "1  [WXGXF, GXFXXXRK, FXXXRK, RKXXI, RKXXIR, KXXI,...   \n",
      "2   [WWRXXK, WRXXK, RXXK, KXXK, KXXKK, KKXXXL, LXXW]   \n",
      "3  [KXKK, KXKKXR, KXKKXRW, KKXR, KKXRW, KXRW, KXR...   \n",
      "4  [MRXXW, MRXXWXH, MRXXWXHW, RXXW, RXXWXH, RXXWX...   \n",
      "5  [MXXA, MXXAR, MXXARF, MXXARFW, MXXARFWW, ARFW,...   \n",
      "\n",
      "                                                0.04  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2         [WWRXXK, WRXXK, RXXK, KXXK, KXXKK, KKXXXL]   \n",
      "3  [KXXK, KXXW, WXXXMM, WXXXMMY, WXXXMMYK, MMYK, ...   \n",
      "4  [MRXXW, MRXXWXH, MRXXWXHW, RXXW, RXXWXH, RXXWX...   \n",
      "5                                  [MXXXRF, MXXXRFW]   \n",
      "\n",
      "                                                0.05  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2         [WWRXXK, WRXXK, RXXK, KXXK, KXXKK, KKXXXL]   \n",
      "3              [KXXW, MXYXY, MXYXYXXL, YXYXXL, YXXL]   \n",
      "4  [MRXXW, MRXXWXH, MRXXWXHW, RXXW, RXXWXH, RXXWX...   \n",
      "5                                  [MXXXRF, MXXXRFW]   \n",
      "\n",
      "                                                0.06  \\\n",
      "0                                                 []   \n",
      "1                                                 []   \n",
      "2                                      [KXXK, KXXKK]   \n",
      "3                    [MXYXY, MXYXYXXL, YXYXXL, YXXL]   \n",
      "4  [MRXXW, MRXXWXH, MRXXWXHW, RXXW, RXXWXH, RXXWX...   \n",
      "5                                                 []   \n",
      "\n",
      "                              0.07        0.08        0.09 0.1  \n",
      "0                               []          []          []  []  \n",
      "1                               []          []          []  []  \n",
      "2                    [KXXK, KXXKK]          []          []  []  \n",
      "3  [MXYXY, MXYXYXXL, YXYXXL, YXXL]          []          []  []  \n",
      "4                       [MRXXXXHW]  [MRXXXXHW]  [MRXXXXHW]  []  \n",
      "5                               []          []          []  []  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df_ls)\n",
    "print(df)\n",
    "df.to_csv('./6peptid_threshold.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "排序后的索引： [4 1 2 0 3]\n"
     ]
    }
   ],
   "source": [
    "# 仅仅设置阈值可能不够，rank呢？\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 给定一个由浮点数组成的列表\n",
    "data = [3.2, 1.8, 2.5, 4.0, 0.5]\n",
    "\n",
    "# 使用numpy的argsort函数获取排序后的索引\n",
    "sorted_indices = np.argsort(data)\n",
    "\n",
    "print(\"排序后的索引：\", sorted_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对应位置的大小排序： [3, 1, 2, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 给定一个由浮点数组成的列表\n",
    "data = [3.2, 1.8, 2.5, 4.0, 0.5]\n",
    "\n",
    "# 使用numpy的argsort函数获取排序后的索引\n",
    "sorted_indices = np.argsort(data)\n",
    "\n",
    "# 创建一个新的列表，其中的元素表示原列表对应位置的大小排序\n",
    "size_sorted_list = [0] * len(data)\n",
    "\n",
    "for i, idx in enumerate(sorted_indices):\n",
    "    size_sorted_list[idx] = i\n",
    "\n",
    "print(\"对应位置的大小排序：\", size_sorted_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 2, 0, 3]\n",
      "对应位置的大小排序： [3, 1, 2, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "data = [3.2, 1.8, 2.5, 4.0, 0.5]\n",
    "\n",
    "# 使用sorted()函数对原列表进行排序，同时获取排序后的索引\n",
    "sorted_indices = sorted(range(len(data)), key=lambda i: data[i])\n",
    "# print(sorted_indices)\n",
    "# 创建一个新的列表，其中的元素表示原列表对应位置的大小排序\n",
    "size_sorted_list = [0] * len(data)\n",
    "\n",
    "for i, idx in enumerate(sorted_indices):\n",
    "    size_sorted_list[idx] = i\n",
    "\n",
    "print(\"对应位置的大小排序：\", size_sorted_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank的方法 + abs*value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n",
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_substring_indices(input_string):\n",
    "    # 输入一个字符串，输出一个列表，列表中的元素为该字符串的子串的index区间\n",
    "    indices = []\n",
    "    length = len(input_string)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(i+4,  min(i+9, length+1)):\n",
    "            indices.append([i, j])\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def filterSubstring(grad:list, alpha:float, indexLs:list, seq:str):\n",
    "\n",
    "    sorted_indices = sorted(range(len(grad)), key=lambda i: grad[i])\n",
    "    size_sorted_list = [0] * len(grad)\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        size_sorted_list[idx] = i\n",
    "    size_sorted_list =  [v/np.max(size_sorted_list) for v in size_sorted_list]\n",
    "    \n",
    "    alpha_grad = [grad[i] if v>=alpha else 0 for i,v in  enumerate(size_sorted_list)]\n",
    "    # print(alpha_grad)\n",
    "    # alpha_grad = [v if v>=alpha else 0 for v in grad]\n",
    "    finalLs = []\n",
    "    for i in indexLs:\n",
    "        subGrad = alpha_grad[i[0]:i[1]]\n",
    "        flag = subGrad.count(0)\n",
    "        if flag <= int(len(subGrad)/2)-1:\n",
    "            subSeq = list(seq[i[0]:i[1]])\n",
    "            for j in range(len(subSeq)):\n",
    "                if subGrad[j] == 0:\n",
    "                    subSeq[j] = 'X'\n",
    "            if subSeq[0]!= 'X' and subSeq[-1]!= 'X':\n",
    "                finalLs.append(''.join(subSeq))\n",
    "\n",
    "\n",
    "    return finalLs\n",
    "\n",
    "def find_motif(input_string,grad,alpha):\n",
    "    result = get_substring_indices(input_string)\n",
    "    ls = filterSubstring(grad,alpha=alpha, indexLs = result, seq=input_string)\n",
    "\n",
    "    return ls\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "input_string = \"abcdesdkjlgf\"\n",
    "grad = [.4,.6,.4,0,.4,.6,.4,0,0,.4,.6,.4,]\n",
    "result = get_substring_indices(input_string)\n",
    "ls = filterSubstring(grad,alpha = 0.4, indexLs = result, seq=input_string)\n",
    "print(ls)\n",
    "ls1 = find_motif(input_string=input_string,grad = grad,alpha=0.4)\n",
    "print(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加NBT attention模型\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "# 下面这几行是为了调用NBT att模型\n",
    "from keras.models import load_model\n",
    "from numpy import loadtxt, savetxt\n",
    "import re\n",
    "\n",
    "from Attention import Attention_layer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://pepcalc.com/ppc.php\"\n",
    "\n",
    "mydata = json.loads(\n",
    "    '{\"hideInputFields\": \"no\",\"nTerm\": \"(NH2-)\",\"cTerm\": \"(-COOH)\",\"aaCode\": 0,\"disulphideBonds\": \"\",\"sequence\": \"\"}')\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Content-Length': '<calculated when request is sent>'\n",
    "}\n",
    "\n",
    "\n",
    "mydict = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "myInvDict = dict([val, key] for key, val in mydict.items())\n",
    "sigmoid = torch.sigmoid\n",
    "\n",
    "\n",
    "NBTdict = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_MIC = math.log10(8192)\n",
    "max_mic_buffer = 0.1\n",
    "My_MAX_MIC = math.log10(600)\n",
    "\n",
    "\n",
    "def CosineSimilarity(tensor_1, tensor_2):\n",
    "    tensor_1 = tensor_1.squeeze()\n",
    "    tensor_2 = tensor_2.squeeze()\n",
    "\n",
    "    normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)\n",
    "    normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)\n",
    "    return (normalized_tensor_1 * normalized_tensor_2).sum()\n",
    "    \n",
    "def seq2num(seq):\n",
    "    \n",
    "    seqlist = list(seq)\n",
    "    # print(seq)\n",
    "    length = len(seq)\n",
    "    result = re.findall(r'[BJOUXZ]',seq)\n",
    "    # print(result)\n",
    "    # 如果序列中有这几个氨基酸，则返回空\n",
    "    if result:\n",
    "        return \n",
    "\n",
    "    # 否则正常返回\n",
    "    else:\n",
    "        numlist = [NBTdict[char.upper()] for char in seqlist]\n",
    "        \n",
    "        zeroPad = [0 for i in range(300-length)]\n",
    "        zeroPad.extend(numlist)\n",
    "        zeroPad = np.array(zeroPad)\n",
    "        \n",
    "        return zeroPad\n",
    "\n",
    "\n",
    "def dataProcessPipeline(seq):\n",
    "    # 本函数先把序列转化为0-19组成的序列，然后onehot变化，再padding\n",
    "    # 同时返回padding后的序列以及mask\n",
    "    #print('ori seq',seq)\n",
    "    testest = seq\n",
    "    num_seq = [mydict[character.upper()] for character in seq]\n",
    "\n",
    "    seq = np.array(num_seq,dtype=int)\n",
    "    len = seq.shape[0]\n",
    "    torch_seq = torch.tensor(seq)\n",
    "    if torch.sum(torch_seq[torch_seq<0])!=0:\n",
    "        print(torch_seq[torch_seq<0])\n",
    "        print('wrong seq:',seq)\n",
    "        print(testest)\n",
    "    onehotSeq = torch.nn.functional.one_hot(torch_seq,num_classes=20)\n",
    "    #onehotSeq = torch.nn.functional.one_hot(c\n",
    "    pad = torch.nn.ZeroPad2d(padding=(0,0,0,100-len))\n",
    "    mask = np.zeros(100,dtype = int)\n",
    "    mask[len:]=1\n",
    "    mask = torch.tensor(mask)\n",
    "\n",
    "    pad_seq = pad(onehotSeq) \n",
    "    \n",
    "    \n",
    "    return pad_seq,mask\n",
    "\n",
    "\n",
    "def num2onehot(array2d):\n",
    "    result = torch.zeros_like(array2d)\n",
    "    index = torch.argmax(array2d,dim = -1)\n",
    "    for i in range(index.shape[0]):\n",
    "        result[i,index[i]] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "        df = pd.read_csv(data_path,header=0)\n",
    "        \n",
    "        \n",
    "        print(str(df.shape)+'\\n')\n",
    "        # df = df[df['Length']<=100]\n",
    "        self.df = df\n",
    "        # id = self.df['Length']<100\n",
    "        # self.df = self.df[id]\n",
    "        # print(self.df.shape)\n",
    "        #self.df = self.df.ix[1:]\n",
    "        # self.seqs = list(self.df['Sequence'])\n",
    "        self.seqs = list(self.df['sequence'])\n",
    "\n",
    "        #print(self.seqs.shape)\n",
    "        self.values = self.df['value']\n",
    "        # 数据集的单边阈值设置\n",
    "        self.values[self.values>MAX_MIC] = MAX_MIC\n",
    "        self.values = list(self.values)\n",
    "        #print(self.labels.shape)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "        label = self.values[idex]\n",
    "\n",
    "\n",
    "        return num_seq, mask, label, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "        self.df = pd.read_csv(data_path,header=0)\n",
    "        self.seqs = self.df['Sequence']\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "\n",
    "        return num_seq, mask, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "     def __init__(self, len, d_model=20, dropout=0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(len, d_model)\n",
    "        position = torch.arange(0, len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                                * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "     def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        #x = x + self.pe[:,:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "pe = PositionalEncoding(len=100,d_model = 20)\n",
    "\n",
    "\n",
    "class AttentionNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self,batch_size=128,embedding_size=20,num_tokens=100,num_classes=1,num_heads=4):\n",
    "        super(AttentionNetwork,self).__init__()\n",
    "        self.pe = PositionalEncoding(len=num_tokens,d_model = embedding_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        # self.hidden1 = 20\n",
    "        self.hidden1 = 20\n",
    "        self.hidden2 = 60\n",
    "        self.hidden3 = 20\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # self.hidden2 = 100\n",
    "        # self.hidden3 = 50\n",
    "        # self.hidden4 = 20\n",
    "        # self.dropout = 0.2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.LN = nn.LayerNorm(normalized_shape = self.hidden1)\n",
    "        self.fc1 = nn.Linear(self.embedding_size,self.hidden1)\n",
    "\n",
    "        # self.qfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.kfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.vfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "\n",
    "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1,num_heads = self.num_heads,batch_first=1,dropout=self.dropout)\n",
    "        # 我这里先不用maxpool了\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(self.hidden1*self.num_tokens,self.hidden2)\n",
    "        self.fc3 = nn.Linear(self.hidden2,self.hidden3)\n",
    "        self.new_fc4 = nn.Linear(self.hidden3,self.num_classes)\n",
    "        # self.fc4 = nn.Linear(self.hidden3,self.hidden4)\n",
    "        # self.fc5 = nn.Linear(self.hidden4,self.num_classes)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.softmax = nn.functional.softmax\n",
    "\n",
    "\n",
    "    #这里的X当作对象 有 embedding 和 mask\n",
    "    def forward(self,x,mask):\n",
    "        x = self.pe(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "\n",
    "        mask = mask.to(torch.bool)\n",
    "        x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "\n",
    "\n",
    "        # x = self.LN(x)\n",
    "        # [N 100 20]\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(type(x),x.size)\n",
    "        # x = torch.tensor(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.new_fc4(x)\n",
    "\n",
    "\n",
    "        #return x, w1, w2, w3, w4\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.2 : ['LWWR', 'LWWRK', 'LWWRKA', 'LWWRKAK', 'LWWRKAKW', 'WWRK', 'WWRKA', 'WWRKAK', 'WWRKAKW', 'WWRKAKWK', 'WRKA', 'WRKAK', 'WRKAKW', 'WRKAKWK', 'WRKAKWKR', 'RKAK', 'RKAKW', 'RKAKWK', 'RKAKWKR', 'KAKW', 'KAKWK', 'KAKWKR', 'KAKWKRXI', 'AKWK', 'AKWKR', 'AKWKRXI', 'KWKR', 'KWKRXI', 'WKRXI', 'WKRXIXXR', 'KRXI', 'KRXIXXRM', 'RXIXXRMI', 'IXXRMI', 'IXXRMIR', 'IXXRMIRV', 'RMIR', 'RMIRV', 'RMIRVI', 'RMIRVIG', 'RMIRVIGA', 'MIRV', 'MIRVI', 'MIRVIG', 'MIRVIGA', 'IRVI', 'IRVIG', 'IRVIGA', 'RVIG', 'RVIGA', 'RVIGAXXI', 'VIGA', 'VIGAXXI', 'IGAXXI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.3 : ['LWWXK', 'LWWXKA', 'LWWXKAXW', 'WWXK', 'WWXKA', 'WWXKAXW', 'WWXKAXWK', 'WXKA', 'WXKAXW', 'WXKAXWK', 'WXKAXWKR', 'KAXW', 'KAXWK', 'KAXWKR', 'KAXWKRXI', 'AXWK', 'AXWKR', 'AXWKRXI', 'WKRXI', 'KRXI', 'IXXXMIRV', 'MIRV', 'MIRVI', 'MIRVIG', 'MIRVIGA', 'IRVI', 'IRVIG', 'IRVIGA', 'RVIG', 'RVIGA', 'RVIGAXXI', 'VIGA', 'VIGAXXI', 'IGAXXI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.4 : ['LWWXK', 'LWWXKA', 'LWWXKAXW', 'WWXK', 'WWXKA', 'WWXKAXW', 'WXKA', 'WXKAXW', 'WXKAXWXR', 'KAXW', 'KAXWXR', 'KAXWXRXI', 'IXXXMIRV', 'MIRV', 'MIRVI', 'MIRVIG', 'IRVI', 'IRVIG', 'RVIG', 'RVIGXXXI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.5 : ['LWXXKA', 'LWXXKAXW', 'KAXW', 'KAXWXR', 'KAXWXRXI', 'IXXXMIRV', 'MIRV', 'MIRVI', 'IRVI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.6 : ['MIRV', 'MIRVI', 'IRVI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.7 : ['MIRXI', 'IRXI']\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.8 : []\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.9 : []\n",
      "1.0\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.2 : ['KWLXXF', 'KWLXXFG', 'KWLXXFGK', 'WLXXFG', 'WLXXFGK', 'LXXFGK', 'LXXFGKXR', 'FGKXR', 'FGKXRK', 'FGKXRKI', 'GKXR', 'GKXRK', 'GKXRKI', 'GKXRKIXI', 'KXRK', 'KXRKI', 'KXRKIXI', 'KXRKIXIR', 'RKIXI', 'RKIXIR', 'RKIXIRL', 'RKIXIRLR', 'KIXI', 'KIXIR', 'KIXIRL', 'KIXIRLR', 'KIXIRLRL', 'IXIR', 'IXIRL', 'IXIRLR', 'IXIRLRL', 'IXIRLRLK', 'IRLR', 'IRLRL', 'IRLRLK', 'IRLRLKXK', 'RLRL', 'RLRLK', 'RLRLKXK', 'RLRLKXKK', 'LRLK', 'LRLKXK', 'LRLKXKK', 'LRLKXKKA', 'RLKXK', 'RLKXKK', 'RLKXKKA', 'RLKXKKAF', 'LKXK', 'LKXKK', 'LKXKKA', 'LKXKKAF', 'KXKK', 'KXKKA', 'KXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.3 : ['KWLXXF', 'KWLXXFXK', 'FXKXRK', 'FXKXRKI', 'KXRK', 'KXRKI', 'KXRKIXI', 'KXRKIXIR', 'RKIXI', 'RKIXIR', 'RKIXIRXR', 'KIXI', 'KIXIR', 'KIXIRXR', 'KIXIRXRL', 'IXIR', 'IXIRXR', 'IXIRXRL', 'IXIRXRLK', 'IRXR', 'IRXRL', 'IRXRLK', 'IRXRLKXK', 'RXRL', 'RXRLK', 'RXRLKXK', 'RXRLKXKK', 'RLKXK', 'RLKXKK', 'RLKXKKA', 'RLKXKKAF', 'LKXK', 'LKXKK', 'LKXKKA', 'LKXKKAF', 'KXKK', 'KXKKA', 'KXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.4 : ['KWLXXF', 'KWLXXFXK', 'FXKXRK', 'KXRK', 'RXKXKK', 'RXKXKKA', 'RXKXKKAF', 'KXKK', 'KXKKA', 'KXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.5 : ['KWLXXF', 'RXXXKKAF', 'KKAF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.6 : ['KKXF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.7 : ['KKXF']\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.8 : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.9 : []\n",
      "1.0\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "WWRLWKTLLKAPKKLTGLRRW\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.2 : ['WWRL', 'WWRLW', 'WWRLWK', 'WWRLWKXL', 'WRLW', 'WRLWK', 'WRLWKXL', 'WRLWKXLL', 'RLWK', 'RLWKXL', 'RLWKXLL', 'RLWKXLLK', 'LWKXL', 'LWKXLL', 'LWKXLLK', 'WKXL', 'WKXLL', 'WKXLLK', 'KXLL', 'KXLLK', 'KXLLKXXK', 'LLKXXK', 'LLKXXKK', 'LLKXXKKL', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KXXKKLXG', 'KKLXG', 'KKLXGL', 'KKLXGLR', 'KKLXGLRR', 'KLXG', 'KLXGL', 'KLXGLR', 'KLXGLRR', 'KLXGLRRW', 'LXGL', 'LXGLR', 'LXGLRR', 'LXGLRRW', 'GLRR', 'GLRRW', 'LRRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.3 : ['WWRL', 'WWRLW', 'WWRLWK', 'WRLW', 'WRLWK', 'WRLWKXXL', 'RLWK', 'RLWKXXL', 'RLWKXXLK', 'LWKXXL', 'LWKXXLK', 'WKXXLK', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KKLXXL', 'KKLXXLR', 'KKLXXLRR', 'KLXXLR', 'KLXXLRR', 'KLXXLRRW', 'LXXLRR', 'LXXLRRW', 'LRRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.4 : ['WWRXW', 'WWRXWK', 'WRXW', 'WRXWK', 'WRXWKXXL', 'RXWK', 'RXWKXXLK', 'WKXXLK', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KKLXXL', 'KKLXXLXR', 'KLXXLXRW', 'LXRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.5 : ['WWRXW', 'WWRXWK', 'WRXW', 'WRXWK', 'RXWK', 'LXRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.6 : ['WWRXXK']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.7 : ['WWRXXK']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.8 : []\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.9 : []\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "RKLKKLRWRAGMMYKYVKLK\n",
      "RKLKKLRWRAGMMYKYVKLK 0.2 : ['KXKK', 'KXKKL', 'KXKKLR', 'KXKKLRW', 'KXKKLRWR', 'KKLR', 'KKLRW', 'KKLRWR', 'KLRW', 'KLRWR', 'KLRWRXXM', 'LRWR', 'LRWRXXM', 'LRWRXXMM', 'RWRXXM', 'RWRXXMM', 'RWRXXMMY', 'WRXXMM', 'WRXXMMY', 'WRXXMMYK', 'RXXMMY', 'RXXMMYK', 'RXXMMYKY', 'MMYK', 'MMYKY', 'MMYKYV', 'MMYKYVK', 'MMYKYVKL', 'MYKY', 'MYKYV', 'MYKYVK', 'MYKYVKL', 'MYKYVKLK', 'YKYV', 'YKYVK', 'YKYVKL', 'YKYVKLK', 'KYVK', 'KYVKL', 'KYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.3 : ['KXKK', 'KXKKXR', 'KXKKXRW', 'KXKKXRWR', 'KKXR', 'KKXRW', 'KKXRWR', 'KXRW', 'KXRWR', 'KXRWRXXM', 'RWRXXM', 'RWRXXMM', 'RWRXXMMY', 'WRXXMM', 'WRXXMMY', 'WRXXMMYK', 'RXXMMY', 'RXXMMYK', 'RXXMMYKY', 'MMYK', 'MMYKY', 'MMYKYXK', 'MMYKYXKL', 'MYKY', 'MYKYXK', 'MYKYXKL', 'MYKYXKLK', 'YKYXK', 'YKYXKL', 'YKYXKLK', 'KYXK', 'KYXKL', 'KYXKLK', 'YXKL', 'YXKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.4 : ['KXKK', 'KXKKXXWR', 'KKXXWR', 'WRXXMM', 'WRXXMMY', 'WRXXMMYK', 'RXXMMY', 'RXXMMYK', 'RXXMMYKY', 'MMYK', 'MMYKY', 'MMYKYXK', 'MMYKYXKL', 'MYKY', 'MYKYXK', 'MYKYXKL', 'YKYXK', 'YKYXKL', 'KYXK', 'KYXKL', 'YXKL']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.5 : ['KXKK', 'MMYXY', 'MMYXYXK', 'MMYXYXKL', 'MYXY', 'MYXYXK', 'MYXYXKL', 'YXYXKL', 'YXKL']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.6 : ['KXKK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.7 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.8 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.9 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MRFPWKHWWKKWKWWWKKKR\n",
      "MRFPWKHWWKKWKWWWKKKR 0.2 : ['MRFXW', 'MRFXWK', 'MRFXWKH', 'MRFXWKHW', 'RFXW', 'RFXWK', 'RFXWKH', 'RFXWKHW', 'RFXWKHWW', 'FXWK', 'FXWKH', 'FXWKHW', 'FXWKHWW', 'WKHW', 'WKHWW', 'WKHWWXK', 'WKHWWXKW', 'KHWW', 'KHWWXK', 'KHWWXKW', 'HWWXK', 'HWWXKW', 'WWXK', 'WWXKW', 'WWXKWXXW', 'WXKW', 'WXKWXXWW', 'KWXXWW', 'KWXXWWK', 'KWXXWWKK', 'WXXWWK', 'WXXWWKK', 'WXXWWKKK', 'WWKK', 'WWKKK', 'WWKKKR', 'WKKK', 'WKKKR', 'KKKR']\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.3 : ['MRFXW', 'MRFXWK', 'MRFXWKH', 'MRFXWKHW', 'RFXW', 'RFXWK', 'RFXWKH', 'RFXWKHW', 'FXWK', 'FXWKH', 'FXWKHW', 'WKHW', 'WKHWXXK', 'WKHWXXKW', 'KHWXXK', 'KHWXXKW', 'HWXXKW', 'KWXXWW', 'KWXXWWK', 'WXXWWK', 'WXXWWKXK', 'WWKXK', 'WWKXKR', 'WKXK', 'WKXKR', 'KXKR']\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.4 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXHW', 'WXHW', 'WXXWWK', 'WXXWWKXK', 'WWKXK', 'WWKXKR', 'WKXK', 'WKXKR', 'KXKR']\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.5 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXHW', 'WXHW']\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.6 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXHW', 'WXHW']\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.7 : []\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.8 : []\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 0.9 : []\n",
      "0.9999999999999998\n",
      "MRFPWKHWWKKWKWWWKKKR 1.0 : []\n",
      "0.9999999999999998\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MKKARFWWWVAWKKLLRKKA\n",
      "MKKARFWWWVAWKKLLRKKA 0.2 : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'ARFWWXXA', 'RFWW', 'RFWWXXA', 'RFWWXXAW', 'FWWXXA', 'FWWXXAW', 'WWXXAW', 'WWXXAWXK', 'WXXAWXKL', 'AWXK', 'AWXKL', 'AWXKLL', 'AWXKLLR', 'AWXKLLRK', 'WXKL', 'WXKLL', 'WXKLLR', 'WXKLLRK', 'WXKLLRKK', 'KLLR', 'KLLRK', 'KLLRKK', 'KLLRKKA', 'LLRK', 'LLRKK', 'LLRKKA', 'LRKK', 'LRKKA', 'RKKA']\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.3 : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'RFWWXXXW', 'WXKL', 'WXKLL', 'WXKLLR', 'WXKLLRXK', 'KLLR', 'KLLRXK', 'KLLRXKA', 'LLRXK', 'LLRXKA', 'LRXK', 'LRXKA', 'RXKA']\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.4 : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'LLRXK', 'LLRXKA', 'LRXK', 'LRXKA', 'RXKA']\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.5 : ['MXXARF', 'MXXARFW', 'MXXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'LLRXXA']\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.6 : ['MXXXRFWW', 'RFWW']\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.7 : []\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.8 : []\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 0.9 : []\n",
      "1.0000000000000002\n",
      "MKKARFWWWVAWKKLLRKKA 1.0 : []\n",
      "1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    # \n",
    "    'myAttention': '../../NewModel3_21_output1_Regression/myAttention/mean_0_changeTH_0_0/_AMP0.629_total0.543.pth',\n",
    "\n",
    "}\n",
    "\n",
    "test_model_list = model_list\n",
    "\n",
    "opt_seqls = [\n",
    "\n",
    "'LWWRKAKWKRKIAKRMIRVIGAAKI',                                                                                                                            \n",
    "'KWLGAFGKMRKIAIRLRLKRKKAF',                                                                                                                             \n",
    "'WWRLWKTLLKAPKKLTGLRRW',                                                                                                                             \n",
    "'RKLKKLRWRAGMMYKYVKLK',\n",
    "'MRFPWKHWWKKWKWWWKKKR',\n",
    "'MKKARFWWWVAWKKLLRKKA'\n",
    "]\n",
    "\n",
    "labels = [\n",
    "'myAttention9',\n",
    "'myAttention7',\n",
    "'CNN8',\n",
    "'myAttention9',\n",
    "'myAttention13',\n",
    "'myAttention9'\n",
    "]\n",
    "\n",
    "label_dict = {opt_seqls[i]:labels[i] for i in range(len(opt_seqls))}\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定之前保存的 JSON 文件名\n",
    "file_name = \"/home/user2/pj/AMP_2/attention_model/test_motif/score/seq_score_9_7_reg.json\"\n",
    "\n",
    "\n",
    "with open(file_name, \"r\") as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "score_seq_dict = {}\n",
    "for item in loaded_data:\n",
    "    seq = item['seq']\n",
    "    # print(seq)\n",
    "    score = np.array(item['score'])\n",
    "    score_seq_dict[seq] = score\n",
    "    # print(score.shape)\n",
    "    # draw_weight2(score,seq,'layer1')\n",
    "\n",
    "\n",
    "df_ls = []\n",
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "for seq in opt_seqls:\n",
    "    tseq = seq\n",
    "\n",
    "    # ModelNameList = ['CNN','Transformer','myAttention','RCNN']\n",
    "    ModelNameList = model_list.keys()\n",
    "\n",
    "    gradient = {}\n",
    "    \n",
    "\n",
    "    oriseq = tseq\n",
    "\n",
    "    # 在当前目录生成 该序列的csv 文件\n",
    "    df = pd.DataFrame(columns = ['Sequence','Length','label'])\n",
    "    items = [{'Sequence':oriseq,'Length':len(oriseq)}]\n",
    "    df = df.append(items,ignore_index = 1)\n",
    "    df.to_csv(oriseq+'.csv',index = False)\n",
    "\n",
    "\n",
    "    SeqPath = oriseq+'.csv'\n",
    "\n",
    "\n",
    "\n",
    "    testData1 = TrainDataset(data_path = r'../../myRegressionData/all_balance/mean/test.csv')\n",
    "    test_loader1 = DataLoader(dataset=testData1, batch_size=4,drop_last=True)\n",
    "\n",
    "\n",
    "    for modelName in ModelNameList:\n",
    "\n",
    "        # modelName = 'myAttention'  # to change\n",
    "        iternum = 0\n",
    "\n",
    "        testData = TestDataset(data_path = SeqPath)\n",
    "        test_loader = DataLoader(dataset=testData, batch_size=1)\n",
    "        attmodel = torch.load(model_list[modelName])\n",
    "\n",
    "\n",
    "        attmodel.cuda()\n",
    "        attmodel.zero_grad()\n",
    "\n",
    "        print(modelName,\"_V2:\")\n",
    "\n",
    "            \n",
    "        for data in test_loader: #序列优化 stratergy 1: 全局都用ensamble作为优化目标\n",
    "            resultList = []\n",
    "            # ensamble_values = []\n",
    "            resultSeq = [oriseq]\n",
    "            outMIC = []\n",
    "            # attmodel.zero_grad()\n",
    "            inputs,masks, seqs = data\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            masks = masks.float()\n",
    "            \n",
    "            # inputs = inputs.cuda()\n",
    "            # inputs.requires_grad = True\n",
    "            masks = masks.cuda()\n",
    "            print(seqs[0])\n",
    "\n",
    "            if modelName == 'RCNN':\n",
    "                attmodel.train()\n",
    "            else:\n",
    "                attmodel.eval()\n",
    "    \n",
    "            attmodel.zero_grad()\n",
    "            stdev_spread = 0.1\n",
    "            n_samples = 25\n",
    "            x = inputs[0].detach()\n",
    "            stdev = stdev_spread * (torch.max(x)-torch.min(x))\n",
    "            x = x.numpy() \n",
    "            total_grad = np.zeros_like(x)\n",
    "            for i in range(n_samples):\n",
    "\n",
    "                    # final.append(xx)\n",
    "                noise = np.random.normal(0,stdev,x.shape).astype(np.float32)\n",
    "                x_plus_noise = x + noise\n",
    "                \n",
    "                x_plus_noise = torch.from_numpy(x_plus_noise).cuda()\n",
    "                # x_plus_noise = x_plus_noise + 0.1\n",
    "                x_plus_noise[masks[0]==1] = 0\n",
    "                x_plus_noise = Variable(torch.unsqueeze(x_plus_noise,dim=0), requires_grad = True)\n",
    "                # final.append(x_plus_noise)\n",
    "                if i==0:\n",
    "                    x_plus_noise = Variable(inputs.cuda(), requires_grad = True)\n",
    "            \n",
    "                if modelName == 'lstm_att' or modelName == 'RCNN'or modelName == 'CNN' or modelName == 'Transformer':\n",
    "                    out = attmodel(x_plus_noise)\n",
    "                else:\n",
    "                    out = attmodel(x_plus_noise,masks)\n",
    "\n",
    "                out = out.cpu()\n",
    "                if 'RCNN' in modelName:\n",
    "                    out = out.unsqueeze(0)\n",
    "\n",
    "                conloss = -out\n",
    "\n",
    "                conloss.backward()\n",
    "                grad = x_plus_noise.grad\n",
    "                # if i==0:\n",
    "                #     print(grad)\n",
    "                colindex = masks[0]==1\n",
    "                grad[0][masks[0]==1] = 0\n",
    "                grad = grad[0].cpu().numpy()\n",
    "                \n",
    "                total_grad += grad\n",
    "\n",
    "\n",
    "            avg_grad = total_grad/n_samples\n",
    "            myIndex = [mydict[v] for v in seqs[0]]\n",
    "\n",
    "            mylen = 100-colindex.sum()\n",
    "            # print(mylen)\n",
    "            grad = avg_grad[:mylen]\n",
    "            # grad = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            mag = np.sum(abs(grad),axis=-1).tolist()\n",
    "\n",
    "            # print(np.sum(grad))\n",
    "\n",
    "            value = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            # print(value)\n",
    "            # max_grad = np.max(grad,axis=-1).tolist()\n",
    "            # # grad  =  [value[i]/max_grad[i] for i in range(len(grad))]\n",
    "            grad = [mag[k]*value[k] for k in range(len(value))]\n",
    "            # grad = list(np.exp(grad))\n",
    "\n",
    "            absGrad = np.sum(abs(np.array(grad)))\n",
    "            grad = [v/absGrad for v in grad]\n",
    "            # grad = [ v/sum(grad) for v in grad]\n",
    "            gradient[modelName] = grad\n",
    "    seq_dict = {'sequence': seq,'model':label_dict[seq]}\n",
    "    for k in range(2,11):\n",
    "        alpha = k/10\n",
    "        ls = find_motif(tseq,grad,alpha)\n",
    "        print(tseq,alpha,':',ls)\n",
    "        print(sum(abs(np.array(grad))))\n",
    "        seq_dict[alpha] = ls\n",
    "\n",
    "    df_ls.append(seq_dict)\n",
    "\n",
    "\n",
    "    # print(gradient)\n",
    "    # grad = gradient['myAttention']\n",
    "    # alpha = 0.05\n",
    "    # ls = find_motif(tseq,grad,alpha)\n",
    "    # print(tseq,':',ls)\n",
    "    # print(sum(abs(np.array(grad))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sequence          model  \\\n",
      "0  LWWRKAKWKRKIAKRMIRVIGAAKI   myAttention9   \n",
      "1   KWLGAFGKMRKIAIRLRLKRKKAF   myAttention7   \n",
      "2      WWRLWKTLLKAPKKLTGLRRW           CNN8   \n",
      "3       RKLKKLRWRAGMMYKYVKLK   myAttention9   \n",
      "4       MRFPWKHWWKKWKWWWKKKR  myAttention13   \n",
      "5       MKKARFWWWVAWKKLLRKKA   myAttention9   \n",
      "\n",
      "                                                 0.2  \\\n",
      "0  [LWWR, LWWRK, LWWRKA, LWWRKAK, LWWRKAKW, WWRK,...   \n",
      "1  [KWLXXF, KWLXXFG, KWLXXFGK, WLXXFG, WLXXFGK, L...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WWRLWKXL, WRLW, WRLWK, W...   \n",
      "3  [KXKK, KXKKL, KXKKLR, KXKKLRW, KXKKLRWR, KKLR,...   \n",
      "4  [MRFXW, MRFXWK, MRFXWKH, MRFXWKHW, RFXW, RFXWK...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                 0.3  \\\n",
      "0  [LWWXK, LWWXKA, LWWXKAXW, WWXK, WWXKA, WWXKAXW...   \n",
      "1  [KWLXXF, KWLXXFXK, FXKXRK, FXKXRKI, KXRK, KXRK...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WRLW, WRLWK, WRLWKXXL, R...   \n",
      "3  [KXKK, KXKKXR, KXKKXRW, KXKKXRWR, KKXR, KKXRW,...   \n",
      "4  [MRFXW, MRFXWK, MRFXWKH, MRFXWKHW, RFXW, RFXWK...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                 0.4  \\\n",
      "0  [LWWXK, LWWXKA, LWWXKAXW, WWXK, WWXKA, WWXKAXW...   \n",
      "1  [KWLXXF, KWLXXFXK, FXKXRK, KXRK, RXKXKK, RXKXK...   \n",
      "2  [WWRXW, WWRXWK, WRXW, WRXWK, WRXWKXXL, RXWK, R...   \n",
      "3  [KXKK, KXKKXXWR, KKXXWR, WRXXMM, WRXXMMY, WRXX...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                 0.5  \\\n",
      "0  [LWXXKA, LWXXKAXW, KAXW, KAXWXR, KAXWXRXI, IXX...   \n",
      "1                           [KWLXXF, RXXXKKAF, KKAF]   \n",
      "2           [WWRXW, WWRXWK, WRXW, WRXWK, RXWK, LXRW]   \n",
      "3  [KXKK, MMYXY, MMYXYXK, MMYXYXKL, MYXY, MYXYXK,...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MXXARF, MXXARFW, MXXARFWW, ARFW, ARFWW, RFWW,...   \n",
      "\n",
      "                                                 0.6            0.7 0.8 0.9  \\\n",
      "0                                [MIRV, MIRVI, IRVI]  [MIRXI, IRXI]  []  []   \n",
      "1                                             [KKXF]         [KKXF]  []  []   \n",
      "2                                           [WWRXXK]       [WWRXXK]  []  []   \n",
      "3                                             [KXKK]             []  []  []   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...             []  []  []   \n",
      "5                                   [MXXXRFWW, RFWW]             []  []  []   \n",
      "\n",
      "  1.0  \n",
      "0  []  \n",
      "1  []  \n",
      "2  []  \n",
      "3  []  \n",
      "4  []  \n",
      "5  []  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df_ls)\n",
    "print(df)\n",
    "df.to_csv('./6peptid_threshold_rank_0.2.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank的方法 + abs* (value/|value|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n",
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_substring_indices(input_string):\n",
    "    # 输入一个字符串，输出一个列表，列表中的元素为该字符串的子串的index区间\n",
    "    indices = []\n",
    "    length = len(input_string)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(i+4,  min(i+9, length+1)):\n",
    "            indices.append([i, j])\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def filterSubstring(grad:list, alpha:float, indexLs:list, seq:str):\n",
    "\n",
    "    sorted_indices = sorted(range(len(grad)), key=lambda i: grad[i])\n",
    "    size_sorted_list = [0] * len(grad)\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        size_sorted_list[idx] = i\n",
    "    size_sorted_list =  [v/np.max(size_sorted_list) for v in size_sorted_list]\n",
    "    \n",
    "    alpha_grad = [grad[i] if v>=alpha else 0 for i,v in  enumerate(size_sorted_list)]\n",
    "    # print(alpha_grad)\n",
    "    # alpha_grad = [v if v>=alpha else 0 for v in grad]\n",
    "    finalLs = []\n",
    "    for i in indexLs:\n",
    "        subGrad = alpha_grad[i[0]:i[1]]\n",
    "        flag = subGrad.count(0)\n",
    "        if flag <= int(len(subGrad)/2)-1:\n",
    "            subSeq = list(seq[i[0]:i[1]])\n",
    "            for j in range(len(subSeq)):\n",
    "                if subGrad[j] == 0:\n",
    "                    subSeq[j] = 'X'\n",
    "            if subSeq[0]!= 'X' and subSeq[-1]!= 'X':\n",
    "                finalLs.append(''.join(subSeq))\n",
    "\n",
    "\n",
    "    return finalLs\n",
    "\n",
    "def find_motif(input_string,grad,alpha):\n",
    "    result = get_substring_indices(input_string)\n",
    "    ls = filterSubstring(grad,alpha=alpha, indexLs = result, seq=input_string)\n",
    "\n",
    "    return ls\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "input_string = \"abcdesdkjlgf\"\n",
    "grad = [.4,.6,.4,0,.4,.6,.4,0,0,.4,.6,.4,]\n",
    "result = get_substring_indices(input_string)\n",
    "ls = filterSubstring(grad,alpha = 0.4, indexLs = result, seq=input_string)\n",
    "print(ls)\n",
    "ls1 = find_motif(input_string=input_string,grad = grad,alpha=0.4)\n",
    "print(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/user2/anaconda3/envs/AMP/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# 添加NBT attention模型\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "# 下面这几行是为了调用NBT att模型\n",
    "from keras.models import load_model\n",
    "from numpy import loadtxt, savetxt\n",
    "import re\n",
    "\n",
    "from Attention import Attention_layer\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://pepcalc.com/ppc.php\"\n",
    "\n",
    "mydata = json.loads(\n",
    "    '{\"hideInputFields\": \"no\",\"nTerm\": \"(NH2-)\",\"cTerm\": \"(-COOH)\",\"aaCode\": 0,\"disulphideBonds\": \"\",\"sequence\": \"\"}')\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'application/x-www-form-urlencoded',\n",
    "    'Content-Length': '<calculated when request is sent>'\n",
    "}\n",
    "\n",
    "\n",
    "mydict = {'A':0,'C':1,'D':2,'E':3,'F':4,'G':5,'H':6,'I':7,'K':8,'L':9,'M':10,'N':11,'P':12,'Q':13,'R':14,'S':15,'T':16,'V':17,'W':18,'Y':19}\n",
    "myInvDict = dict([val, key] for key, val in mydict.items())\n",
    "sigmoid = torch.sigmoid\n",
    "\n",
    "\n",
    "NBTdict = {'A':1,'C':2,'D':3,'E':4,'F':5,'G':6,'H':7,'I':8,'K':9,'L':10,'M':11,'N':12,'P':13,'Q':14,'R':15,'S':16,'T':17,'V':18,'W':19,'Y':20}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MAX_MIC = math.log10(8192)\n",
    "max_mic_buffer = 0.1\n",
    "My_MAX_MIC = math.log10(600)\n",
    "\n",
    "\n",
    "def CosineSimilarity(tensor_1, tensor_2):\n",
    "    tensor_1 = tensor_1.squeeze()\n",
    "    tensor_2 = tensor_2.squeeze()\n",
    "\n",
    "    normalized_tensor_1 = tensor_1 / tensor_1.norm(dim=-1, keepdim=True)\n",
    "    normalized_tensor_2 = tensor_2 / tensor_2.norm(dim=-1, keepdim=True)\n",
    "    return (normalized_tensor_1 * normalized_tensor_2).sum()\n",
    "    \n",
    "def seq2num(seq):\n",
    "    \n",
    "    seqlist = list(seq)\n",
    "    # print(seq)\n",
    "    length = len(seq)\n",
    "    result = re.findall(r'[BJOUXZ]',seq)\n",
    "    # print(result)\n",
    "    # 如果序列中有这几个氨基酸，则返回空\n",
    "    if result:\n",
    "        return \n",
    "\n",
    "    # 否则正常返回\n",
    "    else:\n",
    "        numlist = [NBTdict[char.upper()] for char in seqlist]\n",
    "        \n",
    "        zeroPad = [0 for i in range(300-length)]\n",
    "        zeroPad.extend(numlist)\n",
    "        zeroPad = np.array(zeroPad)\n",
    "        \n",
    "        return zeroPad\n",
    "\n",
    "\n",
    "def dataProcessPipeline(seq):\n",
    "    # 本函数先把序列转化为0-19组成的序列，然后onehot变化，再padding\n",
    "    # 同时返回padding后的序列以及mask\n",
    "    #print('ori seq',seq)\n",
    "    testest = seq\n",
    "    num_seq = [mydict[character.upper()] for character in seq]\n",
    "\n",
    "    seq = np.array(num_seq,dtype=int)\n",
    "    len = seq.shape[0]\n",
    "    torch_seq = torch.tensor(seq)\n",
    "    if torch.sum(torch_seq[torch_seq<0])!=0:\n",
    "        print(torch_seq[torch_seq<0])\n",
    "        print('wrong seq:',seq)\n",
    "        print(testest)\n",
    "    onehotSeq = torch.nn.functional.one_hot(torch_seq,num_classes=20)\n",
    "    #onehotSeq = torch.nn.functional.one_hot(c\n",
    "    pad = torch.nn.ZeroPad2d(padding=(0,0,0,100-len))\n",
    "    mask = np.zeros(100,dtype = int)\n",
    "    mask[len:]=1\n",
    "    mask = torch.tensor(mask)\n",
    "\n",
    "    pad_seq = pad(onehotSeq) \n",
    "    \n",
    "    \n",
    "    return pad_seq,mask\n",
    "\n",
    "\n",
    "def num2onehot(array2d):\n",
    "    result = torch.zeros_like(array2d)\n",
    "    index = torch.argmax(array2d,dim = -1)\n",
    "    for i in range(index.shape[0]):\n",
    "        result[i,index[i]] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "        df = pd.read_csv(data_path,header=0)\n",
    "        \n",
    "        \n",
    "        print(str(df.shape)+'\\n')\n",
    "        # df = df[df['Length']<=100]\n",
    "        self.df = df\n",
    "        # id = self.df['Length']<100\n",
    "        # self.df = self.df[id]\n",
    "        # print(self.df.shape)\n",
    "        #self.df = self.df.ix[1:]\n",
    "        # self.seqs = list(self.df['Sequence'])\n",
    "        self.seqs = list(self.df['sequence'])\n",
    "\n",
    "        #print(self.seqs.shape)\n",
    "        self.values = self.df['value']\n",
    "        # 数据集的单边阈值设置\n",
    "        self.values[self.values>MAX_MIC] = MAX_MIC\n",
    "        self.values = list(self.values)\n",
    "        #print(self.labels.shape)\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "        label = self.values[idex]\n",
    "\n",
    "\n",
    "        return num_seq, mask, label, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self,data_path,transform = dataProcessPipeline):\n",
    "        self.df = pd.read_csv(data_path,header=0)\n",
    "        self.seqs = self.df['Sequence']\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __getitem__(self,idex):\n",
    "        seq = self.seqs[idex]\n",
    "        num_seq, mask = self.transform(seq)\n",
    "\n",
    "        return num_seq, mask, seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seqs)\n",
    "\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "     def __init__(self, len, d_model=20, dropout=0):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(len, d_model)\n",
    "        position = torch.arange(0, len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float()\n",
    "                                * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "     def forward(self, x):\n",
    "        x = x + self.pe\n",
    "        #x = x + self.pe[:,:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "pe = PositionalEncoding(len=100,d_model = 20)\n",
    "\n",
    "\n",
    "class AttentionNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self,batch_size=128,embedding_size=20,num_tokens=100,num_classes=1,num_heads=4):\n",
    "        super(AttentionNetwork,self).__init__()\n",
    "        self.pe = PositionalEncoding(len=num_tokens,d_model = embedding_size)\n",
    "        self.batch_size = batch_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.num_tokens = num_tokens\n",
    "        self.num_classes = num_classes\n",
    "        self.num_heads = num_heads\n",
    "        # self.hidden1 = 20\n",
    "        self.hidden1 = 20\n",
    "        self.hidden2 = 60\n",
    "        self.hidden3 = 20\n",
    "        self.dropout = 0.2\n",
    "\n",
    "        # self.hidden2 = 100\n",
    "        # self.hidden3 = 50\n",
    "        # self.hidden4 = 20\n",
    "        # self.dropout = 0.2\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.LN = nn.LayerNorm(normalized_shape = self.hidden1)\n",
    "        self.fc1 = nn.Linear(self.embedding_size,self.hidden1)\n",
    "\n",
    "        # self.qfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.kfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "        # self.vfc = nn.Linear(self.hidden1,self.hidden1)\n",
    "\n",
    "        self.multihead_att = nn.MultiheadAttention(embed_dim=self.hidden1,num_heads = self.num_heads,batch_first=1,dropout=self.dropout)\n",
    "        # 我这里先不用maxpool了\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc2 = nn.Linear(self.hidden1*self.num_tokens,self.hidden2)\n",
    "        self.fc3 = nn.Linear(self.hidden2,self.hidden3)\n",
    "        self.new_fc4 = nn.Linear(self.hidden3,self.num_classes)\n",
    "        # self.fc4 = nn.Linear(self.hidden3,self.hidden4)\n",
    "        # self.fc5 = nn.Linear(self.hidden4,self.num_classes)\n",
    "        self.dropout = nn.Dropout(self.dropout)\n",
    "        self.softmax = nn.functional.softmax\n",
    "\n",
    "\n",
    "    #这里的X当作对象 有 embedding 和 mask\n",
    "    def forward(self,x,mask):\n",
    "        x = self.pe(x)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "\n",
    "        mask = mask.to(torch.bool)\n",
    "        x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "        # x, w1= self.multihead_att.forward(x,x,x,key_padding_mask=mask)\n",
    "\n",
    "\n",
    "        # x = self.LN(x)\n",
    "        # [N 100 20]\n",
    "\n",
    "        \n",
    "        \n",
    "        #print(type(x),x.size)\n",
    "        # x = torch.tensor(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.new_fc4(x)\n",
    "\n",
    "\n",
    "        #return x, w1, w2, w3, w4\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.2 : ['LWWXK', 'LWWXKA', 'LWWXKAK', 'LWWXKAKW', 'WWXK', 'WWXKA', 'WWXKAK', 'WWXKAKW', 'WWXKAKWK', 'WXKA', 'WXKAK', 'WXKAKW', 'WXKAKWK', 'WXKAKWKR', 'KAKW', 'KAKWK', 'KAKWKR', 'KAKWKRK', 'KAKWKRKI', 'AKWK', 'AKWKR', 'AKWKRK', 'AKWKRKI', 'KWKR', 'KWKRK', 'KWKRKI', 'KWKRKIXK', 'WKRK', 'WKRKI', 'WKRKIXK', 'WKRKIXKR', 'KRKI', 'KRKIXK', 'KRKIXKR', 'KRKIXKRM', 'RKIXK', 'RKIXKR', 'RKIXKRM', 'RKIXKRMI', 'KIXK', 'KIXKR', 'KIXKRM', 'KIXKRMI', 'KIXKRMIR', 'IXKR', 'IXKRM', 'IXKRMI', 'IXKRMIR', 'IXKRMIRV', 'KRMI', 'KRMIR', 'KRMIRV', 'KRMIRVI', 'KRMIRVIG', 'RMIR', 'RMIRV', 'RMIRVI', 'RMIRVIG', 'MIRV', 'MIRVI', 'MIRVIG', 'IRVI', 'IRVIG', 'RVIG', 'RVIGXXXI']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.3 : ['LWWXK', 'LWWXKA', 'LWWXKAK', 'LWWXKAKW', 'WWXK', 'WWXKA', 'WWXKAK', 'WWXKAKW', 'WWXKAKWK', 'WXKA', 'WXKAK', 'WXKAKW', 'WXKAKWK', 'KAKW', 'KAKWK', 'KAKWKXK', 'KAKWKXKI', 'AKWK', 'AKWKXK', 'AKWKXKI', 'KWKXK', 'KWKXKI', 'WKXK', 'WKXKI', 'KXKI', 'KIXXXMIR', 'IXXXMIRV', 'MIRV', 'MIRVI', 'MIRVIG', 'IRVI', 'IRVIG', 'RVIG', 'RVIGXXXI']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.4 : ['LWWXK', 'LWWXKXK', 'LWWXKXKW', 'WWXK', 'WWXKXK', 'WWXKXKW', 'WWXKXKWK', 'WXKXKW', 'WXKXKWK', 'KXKW', 'KXKWK', 'KXKWKXK', 'KXKWKXKI', 'KWKXK', 'KWKXKI', 'WKXK', 'WKXKI', 'KXKI', 'KIXXXMIR', 'IXXXMIRV', 'MIRV', 'MIRVI', 'IRVI']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.5 : ['LWWXK', 'LWWXKXXW', 'WWXK', 'WWXKXXWK', 'IXXXMIRV', 'MIRV', 'MIRVI', 'IRVI']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.6 : ['MIRV', 'MIRVI', 'IRVI']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.7 : ['MIRV']\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.8 : []\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.9 : []\n",
      "1.0000000000000002\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 1.0 : []\n",
      "1.0000000000000002\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.2 : ['KWLG', 'KWLGA', 'KWLGAF', 'KWLGAFG', 'KWLGAFGK', 'WLGA', 'WLGAF', 'WLGAFG', 'WLGAFGK', 'LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKXR', 'GAFG', 'GAFGK', 'GAFGKXR', 'GAFGKXRK', 'AFGK', 'AFGKXR', 'AFGKXRK', 'AFGKXRKI', 'FGKXR', 'FGKXRK', 'FGKXRKI', 'FGKXRKIA', 'GKXR', 'GKXRK', 'GKXRKI', 'GKXRKIA', 'GKXRKIAI', 'KXRK', 'KXRKI', 'KXRKIA', 'KXRKIAI', 'KXRKIAIR', 'RKIA', 'RKIAI', 'RKIAIR', 'RKIAIRXR', 'KIAI', 'KIAIR', 'KIAIRXR', 'KIAIRXRL', 'IAIR', 'IAIRXR', 'IAIRXRL', 'AIRXR', 'AIRXRL', 'IRXR', 'IRXRL', 'IRXRLXXK', 'RXRL', 'RXRLXXKK', 'RLXXKK', 'RLXXKKXF', 'KKXF']\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.3 : ['WLGA', 'WLGAF', 'WLGAFG', 'LGAF', 'LGAFG', 'LGAFGXXR', 'GAFG', 'GAFGXXR', 'GAFGXXRK', 'AFGXXR', 'AFGXXRK', 'AFGXXRKI', 'FGXXRK', 'FGXXRKI', 'FGXXRKIA', 'GXXRKI', 'GXXRKIA', 'GXXRKIAI', 'RKIA', 'RKIAI', 'RKIAIR', 'RKIAIRXR', 'KIAI', 'KIAIR', 'KIAIRXR', 'KIAIRXRL', 'IAIR', 'IAIRXR', 'IAIRXRL', 'AIRXR', 'AIRXRL', 'IRXR', 'IRXRL', 'IRXRLXXK', 'RXRL', 'RXRLXXKK', 'RLXXKK', 'RLXXKKXF', 'KKXF']\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.4 : ['WLGA', 'WLGAF', 'LGAF', 'LGAFXXXR', 'GAFXXXRK', 'RKXA', 'RKXAI', 'RKXAIR', 'KXAI', 'KXAIR', 'KXAIRXXL', 'AIRXXL', 'KKXF']\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.5 : ['WLGA', 'WLGAF', 'LGAF', 'LGAFXXXR', 'GAFXXXRK', 'RKXA', 'RKXAI', 'RKXAIR', 'KXAI', 'KXAIR']\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.6 : ['WLGA', 'RXXAIR']\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.7 : []\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.8 : []\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.9 : []\n",
      "1.0000000000000002\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 1.0 : []\n",
      "1.0000000000000002\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "WWRLWKTLLKAPKKLTGLRRW\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.2 : ['WWRL', 'WWRLW', 'WWRLWK', 'WWRLWKXL', 'WRLW', 'WRLWK', 'WRLWKXL', 'WRLWKXLL', 'RLWK', 'RLWKXL', 'RLWKXLL', 'RLWKXLLK', 'LWKXL', 'LWKXLL', 'LWKXLLK', 'LWKXLLKA', 'WKXL', 'WKXLL', 'WKXLLK', 'WKXLLKA', 'KXLL', 'KXLLK', 'KXLLKA', 'KXLLKAXK', 'LLKA', 'LLKAXK', 'LLKAXKK', 'LLKAXKKL', 'LKAXK', 'LKAXKK', 'LKAXKKL', 'KAXK', 'KAXKK', 'KAXKKL', 'AXKK', 'AXKKL', 'AXKKLXXL', 'KKLXXL', 'KKLXXLR', 'KKLXXLRR', 'KLXXLR', 'KLXXLRR', 'KLXXLRRW', 'LXXLRR', 'LXXLRRW', 'LRRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.3 : ['WWRXW', 'WWRXWK', 'WWRXWKXL', 'WRXW', 'WRXWK', 'WRXWKXL', 'WRXWKXLL', 'RXWK', 'RXWKXL', 'RXWKXLL', 'RXWKXLLK', 'WKXL', 'WKXLL', 'WKXLLK', 'KXLL', 'KXLLK', 'KXLLKXXK', 'LLKXXK', 'LLKXXKK', 'LLKXXKKL', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KKLXXL', 'KKLXXLR', 'KKLXXLRR', 'KLXXLR', 'KLXXLRR', 'KLXXLRRW', 'LXXLRR', 'LXXLRRW', 'LRRW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.4 : ['WWRXW', 'WWRXWK', 'WRXW', 'WRXWK', 'WRXWKXXL', 'RXWK', 'RXWKXXLK', 'WKXXLK', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KKLXXL', 'KKLXXLR', 'KLXXLR', 'KLXXLRXW', 'LRXW']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.5 : ['WWRXXK', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KKLXXL']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.6 : ['KXXKKL', 'KKLXXL']\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.7 : []\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.8 : []\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.9 : []\n",
      "1.0\n",
      "WWRLWKTLLKAPKKLTGLRRW 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "RKLKKLRWRAGMMYKYVKLK\n",
      "RKLKKLRWRAGMMYKYVKLK 0.2 : ['KXKK', 'KXKKXR', 'KXKKXRW', 'KXKKXRWR', 'KKXR', 'KKXRW', 'KKXRWR', 'KKXRWRXG', 'KXRW', 'KXRWR', 'KXRWRXG', 'KXRWRXGM', 'RWRXG', 'RWRXGM', 'RWRXGMM', 'RWRXGMMY', 'WRXG', 'WRXGM', 'WRXGMM', 'WRXGMMY', 'WRXGMMYK', 'RXGM', 'RXGMM', 'RXGMMY', 'RXGMMYK', 'RXGMMYKY', 'GMMY', 'GMMYK', 'GMMYKY', 'GMMYKYV', 'GMMYKYVK', 'MMYK', 'MMYKY', 'MMYKYV', 'MMYKYVK', 'MMYKYVKL', 'MYKY', 'MYKYV', 'MYKYVK', 'MYKYVKL', 'MYKYVKLK', 'YKYV', 'YKYVK', 'YKYVKL', 'YKYVKLK', 'KYVK', 'KYVKL', 'KYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.3 : ['KKXXWR', 'KKXXWRXG', 'KXXWRXGM', 'WRXG', 'WRXGM', 'WRXGMM', 'WRXGMMY', 'WRXGMMYK', 'RXGM', 'RXGMM', 'RXGMMY', 'RXGMMYK', 'RXGMMYKY', 'GMMY', 'GMMYK', 'GMMYKY', 'GMMYKYV', 'GMMYKYVK', 'MMYK', 'MMYKY', 'MMYKYV', 'MMYKYVK', 'MMYKYVKL', 'MYKY', 'MYKYV', 'MYKYVK', 'MYKYVKL', 'MYKYVKLK', 'YKYV', 'YKYVK', 'YKYVKL', 'YKYVKLK', 'KYVK', 'KYVKL', 'KYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.4 : ['WXXGMM', 'WXXGMMY', 'GMMY', 'GMMYXY', 'GMMYXYV', 'GMMYXYVK', 'MMYXY', 'MMYXYV', 'MMYXYVK', 'MMYXYVKL', 'MYXY', 'MYXYV', 'MYXYVK', 'MYXYVKL', 'MYXYVKLK', 'YXYV', 'YXYVK', 'YXYVKL', 'YXYVKLK', 'YVKL', 'YVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.5 : ['WXXGMM', 'WXXGMMY', 'GMMY', 'GMMYXXV', 'GMMYXXVK', 'MMYXXV', 'MMYXXVK', 'MMYXXVKL', 'MYXXVK', 'MYXXVKL', 'MYXXVKLK', 'YXXVKL', 'YXXVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.6 : ['MMYXXV', 'MMYXXVK', 'MMYXXVKL', 'MYXXVK', 'MYXXVKL', 'MYXXVKLK', 'YXXVKL', 'YXXVKLK', 'VKLK']\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.7 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.8 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 0.9 : []\n",
      "1.0\n",
      "RKLKKLRWRAGMMYKYVKLK 1.0 : []\n",
      "1.0\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MRFPWKHWWKKWKWWWKKKR\n",
      "MRFPWKHWWKKWKWWWKKKR 0.2 : ['MRFXW', 'MRFXWK', 'MRFXWKH', 'MRFXWKHW', 'RFXW', 'RFXWK', 'RFXWKH', 'RFXWKHW', 'RFXWKHWW', 'FXWK', 'FXWKH', 'FXWKHW', 'FXWKHWW', 'WKHW', 'WKHWW', 'WKHWWXK', 'WKHWWXKW', 'KHWW', 'KHWWXK', 'KHWWXKW', 'HWWXK', 'HWWXKW', 'HWWXKWXW', 'WWXK', 'WWXKW', 'WWXKWXW', 'WWXKWXWW', 'WXKW', 'WXKWXW', 'WXKWXWW', 'WXKWXWWW', 'KWXW', 'KWXWW', 'KWXWWW', 'KWXWWWK', 'WXWW', 'WXWWW', 'WXWWWK', 'WXWWWKXK', 'WWWK', 'WWWKXK', 'WWWKXKR', 'WWKXK', 'WWKXKR', 'WKXK', 'WKXKR', 'KXKR']\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.3 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'RFXWXHWW', 'FXWXHW', 'FXWXHWW', 'WXHW', 'WXHWW', 'WXHWWXXW', 'HWWXXW', 'HWWXXWXW', 'WWXXWXWW', 'WXXWXWWW', 'WXWW', 'WXWWW', 'WXWWWK', 'WXWWWKXK', 'WWWK', 'WWWKXK', 'WWWKXKR', 'WWKXK', 'WWKXKR', 'WKXK', 'WKXKR', 'KXKR']\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.4 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'RFXWXHWW', 'FXWXHW', 'FXWXHWW', 'WXHW', 'WXHWW', 'WWWXXK', 'WWWXXKR', 'WWXXKR']\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.5 : ['MRFXW', 'MRFXWXH', 'MRFXWXHW', 'RFXW', 'RFXWXH', 'RFXWXHW', 'FXWXHW', 'WXHW']\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.6 : ['MRFXXXHW']\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.7 : []\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.8 : []\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 0.9 : []\n",
      "1.0000000000000002\n",
      "MRFPWKHWWKKWKWWWKKKR 1.0 : []\n",
      "1.0000000000000002\n",
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MKKARFWWWVAWKKLLRKKA\n",
      "MKKARFWWWVAWKKLLRKKA 0.2 : ['MKKA', 'MKKAR', 'MKKARF', 'MKKARFW', 'MKKARFWW', 'KKAR', 'KKARF', 'KKARFW', 'KKARFWW', 'KARF', 'KARFW', 'KARFWW', 'ARFW', 'ARFWW', 'ARFWWXXA', 'RFWW', 'RFWWXXA', 'RFWWXXAW', 'FWWXXA', 'FWWXXAW', 'FWWXXAWK', 'WWXXAW', 'WWXXAWK', 'WXXAWK', 'WXXAWKXL', 'AWKXL', 'AWKXLL', 'AWKXLLR', 'AWKXLLRK', 'WKXL', 'WKXLL', 'WKXLLR', 'WKXLLRK', 'WKXLLRKK', 'KXLL', 'KXLLR', 'KXLLRK', 'KXLLRKK', 'LLRK', 'LLRKK', 'LRKK']\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.3 : ['MKXA', 'MKXAR', 'MKXARF', 'MKXARFW', 'MKXARFWW', 'KXAR', 'KXARF', 'KXARFW', 'KXARFWW', 'ARFW', 'ARFWW', 'ARFWWXXA', 'RFWW', 'RFWWXXA', 'RFWWXXAW', 'FWWXXA', 'FWWXXAW', 'WWXXAW', 'AWXXLL', 'AWXXLLR', 'AWXXLLRK', 'WXXLLR', 'WXXLLRK', 'WXXLLRKK', 'LLRK', 'LLRKK', 'LRKK']\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.4 : ['MXXARF', 'MXXARFW', 'MXXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'RFWWXXXW', 'WXXLLR', 'WXXLLRK', 'WXXLLRKK', 'LLRK', 'LLRKK', 'LRKK']\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.5 : ['MXXARF', 'MXXARFW', 'MXXARFWW', 'ARFW', 'ARFWW', 'RFWW', 'LLRXK', 'LRXK']\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.6 : ['MXXARF', 'MXXARFW', 'ARFW']\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.7 : []\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.8 : []\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 0.9 : []\n",
      "1.0\n",
      "MKKARFWWWVAWKKLLRKKA 1.0 : []\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    # \n",
    "    'myAttention': '../../NewModel3_21_output1_Regression/myAttention/mean_0_changeTH_0_0/_AMP0.629_total0.543.pth',\n",
    "\n",
    "}\n",
    "\n",
    "test_model_list = model_list\n",
    "\n",
    "opt_seqls = [\n",
    "\n",
    "'LWWRKAKWKRKIAKRMIRVIGAAKI',                                                                                                                            \n",
    "'KWLGAFGKMRKIAIRLRLKRKKAF',                                                                                                                             \n",
    "'WWRLWKTLLKAPKKLTGLRRW',                                                                                                                             \n",
    "'RKLKKLRWRAGMMYKYVKLK',\n",
    "'MRFPWKHWWKKWKWWWKKKR',\n",
    "'MKKARFWWWVAWKKLLRKKA'\n",
    "]\n",
    "\n",
    "labels = [\n",
    "'myAttention9',\n",
    "'myAttention7',\n",
    "'CNN8',\n",
    "'myAttention9',\n",
    "'myAttention13',\n",
    "'myAttention9'\n",
    "]\n",
    "\n",
    "label_dict = {opt_seqls[i]:labels[i] for i in range(len(opt_seqls))}\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定之前保存的 JSON 文件名\n",
    "file_name = \"/home/user2/pj/AMP_2/attention_model/test_motif/score/seq_score_9_7_reg.json\"\n",
    "\n",
    "\n",
    "with open(file_name, \"r\") as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "score_seq_dict = {}\n",
    "for item in loaded_data:\n",
    "    seq = item['seq']\n",
    "    # print(seq)\n",
    "    score = np.array(item['score'])\n",
    "    score_seq_dict[seq] = score\n",
    "    # print(score.shape)\n",
    "    # draw_weight2(score,seq,'layer1')\n",
    "\n",
    "\n",
    "df_ls = []\n",
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "for seq in opt_seqls:\n",
    "    tseq = seq\n",
    "\n",
    "    # ModelNameList = ['CNN','Transformer','myAttention','RCNN']\n",
    "    ModelNameList = model_list.keys()\n",
    "\n",
    "    gradient = {}\n",
    "    \n",
    "\n",
    "    oriseq = tseq\n",
    "\n",
    "    # 在当前目录生成 该序列的csv 文件\n",
    "    df = pd.DataFrame(columns = ['Sequence','Length','label'])\n",
    "    items = [{'Sequence':oriseq,'Length':len(oriseq)}]\n",
    "    df = df.append(items,ignore_index = 1)\n",
    "    df.to_csv(oriseq+'.csv',index = False)\n",
    "\n",
    "\n",
    "    SeqPath = oriseq+'.csv'\n",
    "\n",
    "\n",
    "\n",
    "    testData1 = TrainDataset(data_path = r'../../myRegressionData/all_balance/mean/test.csv')\n",
    "    test_loader1 = DataLoader(dataset=testData1, batch_size=4,drop_last=True)\n",
    "\n",
    "\n",
    "    for modelName in ModelNameList:\n",
    "\n",
    "        # modelName = 'myAttention'  # to change\n",
    "        iternum = 0\n",
    "\n",
    "        testData = TestDataset(data_path = SeqPath)\n",
    "        test_loader = DataLoader(dataset=testData, batch_size=1)\n",
    "        attmodel = torch.load(model_list[modelName])\n",
    "\n",
    "\n",
    "        attmodel.cuda()\n",
    "        attmodel.zero_grad()\n",
    "\n",
    "        print(modelName,\"_V2:\")\n",
    "\n",
    "            \n",
    "        for data in test_loader: #序列优化 stratergy 1: 全局都用ensamble作为优化目标\n",
    "            resultList = []\n",
    "            # ensamble_values = []\n",
    "            resultSeq = [oriseq]\n",
    "            outMIC = []\n",
    "            # attmodel.zero_grad()\n",
    "            inputs,masks, seqs = data\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            masks = masks.float()\n",
    "            \n",
    "            # inputs = inputs.cuda()\n",
    "            # inputs.requires_grad = True\n",
    "            masks = masks.cuda()\n",
    "            print(seqs[0])\n",
    "\n",
    "            if modelName == 'RCNN':\n",
    "                attmodel.train()\n",
    "            else:\n",
    "                attmodel.eval()\n",
    "    \n",
    "            attmodel.zero_grad()\n",
    "            stdev_spread = 0.1\n",
    "            n_samples = 25\n",
    "            x = inputs[0].detach()\n",
    "            stdev = stdev_spread * (torch.max(x)-torch.min(x))\n",
    "            x = x.numpy() \n",
    "            total_grad = np.zeros_like(x)\n",
    "            for i in range(n_samples):\n",
    "\n",
    "                    # final.append(xx)\n",
    "                noise = np.random.normal(0,stdev,x.shape).astype(np.float32)\n",
    "                x_plus_noise = x + noise\n",
    "                \n",
    "                x_plus_noise = torch.from_numpy(x_plus_noise).cuda()\n",
    "                # x_plus_noise = x_plus_noise + 0.1\n",
    "                x_plus_noise[masks[0]==1] = 0\n",
    "                x_plus_noise = Variable(torch.unsqueeze(x_plus_noise,dim=0), requires_grad = True)\n",
    "                # final.append(x_plus_noise)\n",
    "                if i==0:\n",
    "                    x_plus_noise = Variable(inputs.cuda(), requires_grad = True)\n",
    "            \n",
    "                if modelName == 'lstm_att' or modelName == 'RCNN'or modelName == 'CNN' or modelName == 'Transformer':\n",
    "                    out = attmodel(x_plus_noise)\n",
    "                else:\n",
    "                    out = attmodel(x_plus_noise,masks)\n",
    "\n",
    "                out = out.cpu()\n",
    "                if 'RCNN' in modelName:\n",
    "                    out = out.unsqueeze(0)\n",
    "\n",
    "                conloss = -out\n",
    "\n",
    "                conloss.backward()\n",
    "                grad = x_plus_noise.grad\n",
    "                # if i==0:\n",
    "                #     print(grad)\n",
    "                colindex = masks[0]==1\n",
    "                grad[0][masks[0]==1] = 0\n",
    "                grad = grad[0].cpu().numpy()\n",
    "                \n",
    "                total_grad += grad\n",
    "\n",
    "\n",
    "            avg_grad = total_grad/n_samples\n",
    "            myIndex = [mydict[v] for v in seqs[0]]\n",
    "\n",
    "            mylen = 100-colindex.sum()\n",
    "            # print(mylen)\n",
    "            grad = avg_grad[:mylen]\n",
    "            # grad = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            mag = np.sum(abs(grad),axis=-1).tolist()\n",
    "\n",
    "            # print(np.sum(grad))\n",
    "\n",
    "            value = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            value = [1 if v>=0 else -1 for v in value]\n",
    "            # print(value)\n",
    "            # max_grad = np.max(grad,axis=-1).tolist()\n",
    "            # # grad  =  [value[i]/max_grad[i] for i in range(len(grad))]\n",
    "            grad = [mag[k]*value[k] for k in range(len(value))]\n",
    "            # grad = list(np.exp(grad))\n",
    "\n",
    "            absGrad = np.sum(abs(np.array(grad)))\n",
    "            grad = [v/absGrad for v in grad]\n",
    "            # grad = [ v/sum(grad) for v in grad]\n",
    "            gradient[modelName] = grad\n",
    "    seq_dict = {'sequence': seq,'model':label_dict[seq]}\n",
    "    for k in range(2,11):\n",
    "        alpha = k/10\n",
    "        ls = find_motif(tseq,grad,alpha)\n",
    "        print(tseq,alpha,':',ls)\n",
    "        print(sum(abs(np.array(grad))))\n",
    "        seq_dict[alpha] = ls\n",
    "\n",
    "    df_ls.append(seq_dict)\n",
    "\n",
    "\n",
    "    # print(gradient)\n",
    "    # grad = gradient['myAttention']\n",
    "    # alpha = 0.05\n",
    "    # ls = find_motif(tseq,grad,alpha)\n",
    "    # print(tseq,':',ls)\n",
    "    # print(sum(abs(np.array(grad))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sequence          model  \\\n",
      "0  LWWRKAKWKRKIAKRMIRVIGAAKI   myAttention9   \n",
      "1   KWLGAFGKMRKIAIRLRLKRKKAF   myAttention7   \n",
      "2      WWRLWKTLLKAPKKLTGLRRW           CNN8   \n",
      "3       RKLKKLRWRAGMMYKYVKLK   myAttention9   \n",
      "4       MRFPWKHWWKKWKWWWKKKR  myAttention13   \n",
      "5       MKKARFWWWVAWKKLLRKKA   myAttention9   \n",
      "\n",
      "                                                 0.2  \\\n",
      "0  [LWWXK, LWWXKA, LWWXKAK, LWWXKAKW, WWXK, WWXKA...   \n",
      "1  [KWLG, KWLGA, KWLGAF, KWLGAFG, KWLGAFGK, WLGA,...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WWRLWKXL, WRLW, WRLWK, W...   \n",
      "3  [KXKK, KXKKXR, KXKKXRW, KXKKXRWR, KKXR, KKXRW,...   \n",
      "4  [MRFXW, MRFXWK, MRFXWKH, MRFXWKHW, RFXW, RFXWK...   \n",
      "5  [MKKA, MKKAR, MKKARF, MKKARFW, MKKARFWW, KKAR,...   \n",
      "\n",
      "                                                 0.3  \\\n",
      "0  [LWWXK, LWWXKA, LWWXKAK, LWWXKAKW, WWXK, WWXKA...   \n",
      "1  [WLGA, WLGAF, WLGAFG, LGAF, LGAFG, LGAFGXXR, G...   \n",
      "2  [WWRXW, WWRXWK, WWRXWKXL, WRXW, WRXWK, WRXWKXL...   \n",
      "3  [KKXXWR, KKXXWRXG, KXXWRXGM, WRXG, WRXGM, WRXG...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MKXA, MKXAR, MKXARF, MKXARFW, MKXARFWW, KXAR,...   \n",
      "\n",
      "                                                 0.4  \\\n",
      "0  [LWWXK, LWWXKXK, LWWXKXKW, WWXK, WWXKXK, WWXKX...   \n",
      "1  [WLGA, WLGAF, LGAF, LGAFXXXR, GAFXXXRK, RKXA, ...   \n",
      "2  [WWRXW, WWRXWK, WRXW, WRXWK, WRXWKXXL, RXWK, R...   \n",
      "3  [WXXGMM, WXXGMMY, GMMY, GMMYXY, GMMYXYV, GMMYX...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MXXARF, MXXARFW, MXXARFWW, ARFW, ARFWW, RFWW,...   \n",
      "\n",
      "                                                 0.5  \\\n",
      "0  [LWWXK, LWWXKXXW, WWXK, WWXKXXWK, IXXXMIRV, MI...   \n",
      "1  [WLGA, WLGAF, LGAF, LGAFXXXR, GAFXXXRK, RKXA, ...   \n",
      "2          [WWRXXK, LKXXKK, LKXXKKL, KXXKKL, KKLXXL]   \n",
      "3  [WXXGMM, WXXGMMY, GMMY, GMMYXXV, GMMYXXVK, MMY...   \n",
      "4  [MRFXW, MRFXWXH, MRFXWXHW, RFXW, RFXWXH, RFXWX...   \n",
      "5  [MXXARF, MXXARFW, MXXARFWW, ARFW, ARFWW, RFWW,...   \n",
      "\n",
      "                                                 0.6     0.7 0.8 0.9 1.0  \n",
      "0                                [MIRV, MIRVI, IRVI]  [MIRV]  []  []  []  \n",
      "1                                     [WLGA, RXXAIR]      []  []  []  []  \n",
      "2                                   [KXXKKL, KKLXXL]      []  []  []  []  \n",
      "3  [MMYXXV, MMYXXVK, MMYXXVKL, MYXXVK, MYXXVKL, M...      []  []  []  []  \n",
      "4                                         [MRFXXXHW]      []  []  []  []  \n",
      "5                            [MXXARF, MXXARFW, ARFW]      []  []  []  []  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(df_ls)\n",
    "print(df)\n",
    "df.to_csv('./6peptid_sign_only_threshold_rank_0.2.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n",
      "['bXXesd', 'esdXXl', 'esdXXlg', 'esdXXlgf', 'sdXXlg', 'sdXXlgf', 'dXXlgf']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_substring_indices(input_string):\n",
    "    # 输入一个字符串，输出一个列表，列表中的元素为该字符串的子串的index区间\n",
    "    indices = []\n",
    "    length = len(input_string)\n",
    "    \n",
    "    for i in range(length):\n",
    "        for j in range(i+4,  min(i+9, length+1)):\n",
    "            indices.append([i, j])\n",
    "    \n",
    "    return indices\n",
    "\n",
    "def filterSubstring(grad:list, alpha:float, indexLs:list, seq:str):\n",
    "\n",
    "    sorted_indices = sorted(range(len(grad)), key=lambda i: grad[i])\n",
    "    size_sorted_list = [0] * len(grad)\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        size_sorted_list[idx] = i\n",
    "    size_sorted_list =  [v/np.max(size_sorted_list) for v in size_sorted_list]\n",
    "    \n",
    "    alpha_grad = [grad[i] if v>=alpha else 0 for i,v in  enumerate(size_sorted_list)]\n",
    "    # print(alpha_grad)\n",
    "    # alpha_grad = [v if v>=alpha else 0 for v in grad]\n",
    "    finalLs = []\n",
    "    for i in indexLs:\n",
    "        subGrad = alpha_grad[i[0]:i[1]]\n",
    "        flag = subGrad.count(0)\n",
    "        if flag <= int(len(subGrad)/2)-1:\n",
    "            subSeq = list(seq[i[0]:i[1]])\n",
    "            for j in range(len(subSeq)):\n",
    "                if subGrad[j] == 0:\n",
    "                    subSeq[j] = 'X'\n",
    "            if subSeq[0]!= 'X' and subSeq[-1]!= 'X':\n",
    "                finalLs.append(''.join(subSeq))\n",
    "\n",
    "\n",
    "    return finalLs\n",
    "\n",
    "def find_motif(input_string,grad,alpha):\n",
    "    result = get_substring_indices(input_string)\n",
    "    ls = filterSubstring(grad,alpha=alpha, indexLs = result, seq=input_string)\n",
    "\n",
    "    return ls\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "input_string = \"abcdesdkjlgf\"\n",
    "grad = [.4,.6,.4,0,.4,.6,.4,0,0,.4,.6,.4,]\n",
    "result = get_substring_indices(input_string)\n",
    "ls = filterSubstring(grad,alpha = 0.4, indexLs = result, seq=input_string)\n",
    "print(ls)\n",
    "ls1 = find_motif(input_string=input_string,grad = grad,alpha=0.4)\n",
    "print(ls1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.2 : ['LXXRKA', 'LXXRKAK', 'LXXRKAKW', 'RKAK', 'RKAKW', 'RKAKWK', 'RKAKWKXK', 'KAKW', 'KAKWK', 'KAKWKXK', 'KAKWKXKI', 'AKWK', 'AKWKXK', 'AKWKXKI', 'AKWKXKIA', 'KWKXK', 'KWKXKI', 'KWKXKIA', 'KWKXKIAK', 'WKXK', 'WKXKI', 'WKXKIA', 'WKXKIAK', 'KXKI', 'KXKIA', 'KXKIAK', 'KXKIAKXM', 'KIAK', 'KIAKXM', 'KIAKXMI', 'IAKXM', 'IAKXMI', 'IAKXMIXV', 'AKXM', 'AKXMI', 'AKXMIXV', 'KXMI', 'KXMIXV', 'KXMIXVXG', 'MIXV', 'MIXVXG']\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.3 : ['KAKXK', 'KAKXKXK', 'KAKXKXKI', 'AKXK', 'AKXKXK', 'AKXKXKI', 'AKXKXKIA', 'KXKXKI', 'KXKXKIA', 'KXKXKIAK', 'KXKI', 'KXKIA', 'KXKIAK', 'KXKIAKXM', 'KIAK', 'KIAKXM', 'KIAKXMI', 'IAKXM', 'IAKXMI', 'AKXM', 'AKXMI', 'KXMI']\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.4 : ['KAKXK', 'KAKXKXK', 'KAKXKXKI', 'AKXK', 'AKXKXK', 'AKXKXKI', 'AKXKXKIA', 'KXKXKI', 'KXKXKIA', 'KXKXKIAK', 'KXKI', 'KXKIA', 'KXKIAK', 'KXKIAKXM', 'KIAK', 'KIAKXM', 'KIAKXMI', 'IAKXM', 'IAKXMI', 'AKXM', 'AKXMI', 'KXMI']\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.5 : ['KAKXK', 'KAKXKXK', 'KAKXKXKI', 'AKXK', 'AKXKXK', 'AKXKXKI', 'AKXKXKIA', 'KXKXKI', 'KXKXKIA', 'KXKXKIAK', 'KXKI', 'KXKIA', 'KXKIAK', 'KXKIAKXM', 'KIAK', 'KIAKXM', 'KIAKXMI', 'IAKXM', 'IAKXMI', 'AKXM', 'AKXMI', 'KXMI']\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.6 : ['IXKXMI', 'KXMI']\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.7 : []\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.8 : []\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 0.9 : []\n",
      "4.2\n",
      "LWWRKAKWKRKIAKRMIRVIGAAKI 1.0 : []\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.2 : ['KWLG', 'KWLGA', 'KWLGAF', 'KWLGAFG', 'KWLGAFGK', 'WLGA', 'WLGAF', 'WLGAFG', 'WLGAFGK', 'WLGAFGKM', 'LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'FGKMXXIA', 'GKMXXI', 'GKMXXIA', 'GKMXXIAI', 'KMXXIA', 'KMXXIAI', 'MXXIAI', 'MXXIAIXL', 'IAIXL', 'IAIXLXL', 'AIXL', 'AIXLXL', 'LXLXXKKA', 'LXXKKA', 'LXXKKAF', 'KKAF']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.3 : ['KWLG', 'KWLGA', 'KWLGAF', 'KWLGAFG', 'KWLGAFGK', 'WLGA', 'WLGAF', 'WLGAFG', 'WLGAFGK', 'WLGAFGKM', 'LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'FGKMXXIA', 'GKMXXI', 'GKMXXIA', 'GKMXXIAI', 'KMXXIA', 'KMXXIAI', 'MXXIAI', 'MXXIAIXL', 'IAIXL', 'IAIXLXL', 'AIXL', 'AIXLXL']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.4 : ['KXLG', 'KXLGA', 'KXLGAF', 'KXLGAFG', 'KXLGAFGK', 'LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'FGKMXXIA', 'GKMXXI', 'GKMXXIA', 'GKMXXIAI', 'KMXXIA', 'KMXXIAI', 'MXXIAI', 'MXXIAIXL', 'IAIXL', 'AIXL']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.5 : ['LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'FGKMXXIA', 'GKMXXI', 'GKMXXIA', 'GKMXXIAI', 'KMXXIA', 'KMXXIAI', 'MXXIAI', 'MXXIAIXL', 'IAIXL', 'AIXL']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.6 : ['LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'GKMXXI']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.7 : ['LGAF', 'LGAFG', 'LGAFGK', 'LGAFGKM', 'GAFG', 'GAFGK', 'GAFGKM', 'AFGK', 'AFGKM', 'AFGKMXXI', 'FGKM', 'FGKMXXI', 'GKMXXI']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.8 : ['LGXF', 'LGXFG', 'LGXFGXM', 'GXFG', 'GXFGXM', 'FGXM']\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 0.9 : []\n",
      "4.2\n",
      "KWLGAFGKMRKIAIRLRLKRKKAF 1.0 : []\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.2 : ['WWRL', 'WWRLW', 'WWRLWK', 'WWRLWKT', 'WWRLWKTL', 'WRLW', 'WRLWK', 'WRLWKT', 'WRLWKTL', 'WRLWKTLL', 'RLWK', 'RLWKT', 'RLWKTL', 'RLWKTLL', 'RLWKTLLK', 'LWKT', 'LWKTL', 'LWKTLL', 'LWKTLLK', 'WKTL', 'WKTLL', 'WKTLLK', 'KTLL', 'KTLLK', 'KTLLKXXK', 'TLLK', 'TLLKXXK', 'TLLKXXKK', 'LLKXXK', 'LLKXXKK', 'LLKXXKKL', 'LKXXKK', 'LKXXKKL', 'KXXKKL', 'KXXKKLXG', 'KKLXG', 'KKLXGL', 'KLXG', 'KLXGL', 'LXGL']\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.3 : ['WWXL', 'WWXLW', 'WWXLWK', 'WWXLWKT', 'WWXLWKTL', 'WXLW', 'WXLWK', 'WXLWKT', 'WXLWKTL', 'WXLWKTLL', 'LWKT', 'LWKTL', 'LWKTLL', 'LWKTLLK', 'WKTL', 'WKTLL', 'WKTLLK', 'KTLL', 'KTLLK', 'KTLLKXXK', 'TLLK', 'TLLKXXK', 'TLLKXXKK', 'LLKXXK', 'LLKXXKK', 'LKXXKK']\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.4 : ['LXKT']\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.5 : ['LXKT']\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.6 : ['LXKT']\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.7 : []\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.8 : []\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 0.9 : []\n",
      "4.2\n",
      "WWRLWKTLLKAPKKLTGLRRW 1.0 : []\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.2 : ['RKLK', 'RKLKK', 'RKLKKL', 'RKLKKLR', 'KLKK', 'KLKKL', 'KLKKLR', 'KLKKLRXR', 'LKKL', 'LKKLR', 'LKKLRXR', 'KKLR', 'KKLRXR', 'KKLRXRXG', 'KLRXR', 'KLRXRXG', 'KLRXRXGM', 'LRXR', 'LRXRXG', 'LRXRXGM', 'RXRXGM', 'RXRXGMXY', 'RXGM', 'RXGMXY', 'RXGMXYK', 'GMXY', 'GMXYK', 'GMXYKXXK', 'MXYK', 'MXYKXXKL', 'YKXXKL', 'YKXXKLK', 'KXXKLK']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.3 : ['RKXK', 'RKXKK', 'RKXKKL', 'RKXKKLR', 'KXKK', 'KXKKL', 'KXKKLR', 'KXKKLRXR', 'KKLR', 'KKLRXR', 'KKLRXRXG', 'KLRXR', 'KLRXRXG', 'KLRXRXGM', 'LRXR', 'LRXRXG', 'LRXRXGM', 'RXRXGM', 'RXRXGMXY', 'RXGM', 'RXGMXY', 'RXGMXYK', 'GMXY', 'GMXYK', 'GMXYKXXK', 'MXYK']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.4 : ['RKXK', 'RKXKK', 'RKXKKL', 'RKXKKLR', 'KXKK', 'KXKKL', 'KXKKLR', 'KKLR', 'KKLRXXXG']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.5 : ['RKXK', 'RKXKK', 'RKXKKL', 'RKXKKLR', 'KXKK', 'KXKKL', 'KXKKLR', 'KKLR', 'KKLRXXXG']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.6 : ['RKXK', 'RKXKK', 'RKXKKL', 'KXKK', 'KXKKL']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.7 : ['RKXK', 'RKXKK', 'RKXKKL', 'KXKK', 'KXKKL']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.8 : ['RKXK', 'RKXKK', 'RKXKKL', 'KXKK', 'KXKKL']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 0.9 : ['KXKK', 'KXKKL']\n",
      "4.2\n",
      "RKLKKLRWRAGMMYKYVKLK 1.0 : []\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.2 : ['MRFP', 'MRFPW', 'MRFPWK', 'MRFPWKH', 'MRFPWKHW', 'RFPW', 'RFPWK', 'RFPWKH', 'RFPWKHW', 'RFPWKHWW', 'FPWK', 'FPWKH', 'FPWKHW', 'FPWKHWW', 'FPWKHWWK', 'PWKH', 'PWKHW', 'PWKHWW', 'PWKHWWK', 'PWKHWWKK', 'WKHW', 'WKHWW', 'WKHWWK', 'WKHWWKK', 'KHWW', 'KHWWK', 'KHWWKK', 'KHWWKKXK', 'HWWK', 'HWWKK', 'HWWKKXK', 'HWWKKXKW', 'WWKK', 'WWKKXK', 'WWKKXKW', 'WKKXK', 'WKKXKW', 'KKXK', 'KKXKW', 'KKXKWXXK', 'KXKW', 'KXKWXXKK', 'KWXXKK', 'KWXXKKK', 'WXXKKK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.3 : ['MRXP', 'MRXPXK', 'MRXPXKH', 'MRXPXKHW', 'RXPXKH', 'RXPXKHW', 'RXPXKHWW', 'PXKH', 'PXKHW', 'PXKHWW', 'PXKHWWK', 'PXKHWWKK', 'KHWW', 'KHWWK', 'KHWWKK', 'KHWWKKXK', 'HWWK', 'HWWKK', 'HWWKKXK', 'HWWKKXKW', 'WWKK', 'WWKKXK', 'WWKKXKW', 'WKKXK', 'WKKXKW', 'KKXK', 'KKXKW', 'KKXKWXXK', 'KXKW', 'KXKWXXKK', 'KWXXKK', 'KWXXKKK', 'WXXKKK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.4 : ['MRXP', 'MRXPXK', 'MRXPXKH', 'MRXPXKHW', 'RXPXKH', 'RXPXKHW', 'RXPXKHWW', 'PXKH', 'PXKHW', 'PXKHWW', 'PXKHWWK', 'PXKHWWKK', 'KHWW', 'KHWWK', 'KHWWKK', 'KHWWKKXK', 'HWWK', 'HWWKK', 'HWWKKXK', 'WWKK', 'WWKKXK', 'WKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.5 : ['MRXP', 'MRXPXK', 'MRXPXKH', 'MRXPXKHW', 'RXPXKH', 'RXPXKHW', 'PXKH', 'PXKHW', 'PXKHWXK', 'PXKHWXKK', 'KHWXK', 'KHWXKK', 'KHWXKKXK', 'HWXK', 'HWXKK', 'HWXKKXK', 'WXKK', 'WXKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.6 : ['MRXXXKHW', 'KHWXK', 'KHWXKK', 'KHWXKKXK', 'HWXK', 'HWXKK', 'HWXKKXK', 'WXKK', 'WXKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.7 : ['KHXXKK', 'KHXXKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.8 : ['KHXXKK', 'KHXXKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 0.9 : ['KHXXKK', 'KHXXKKXK', 'KKXK']\n",
      "4.2\n",
      "MRFPWKHWWKKWKWWWKKKR 1.0 : []\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.2 : ['MKKXR', 'MKKXRF', 'MKKXRFW', 'MKKXRFWW', 'KKXR', 'KKXRF', 'KKXRFW', 'KKXRFWW', 'KKXRFWWW', 'KXRF', 'KXRFW', 'KXRFWW', 'KXRFWWW', 'KXRFWWWV', 'RFWW', 'RFWWW', 'RFWWWV', 'RFWWWVA', 'FWWW', 'FWWWV', 'FWWWVA', 'FWWWVAXK', 'WWWV', 'WWWVA', 'WWWVAXK', 'WWWVAXKK', 'WWVA', 'WWVAXK', 'WWVAXKK', 'WVAXK', 'WVAXKK', 'WVAXKKXL', 'VAXK', 'VAXKK', 'VAXKKXL', 'AXKK', 'AXKKXL', 'AXKKXLXK', 'KKXL', 'KKXLXK', 'KKXLXKK', 'KXLXKK', 'LXKK']\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.3 : ['MKKXR', 'MKKXRF', 'MKKXRFW', 'MKKXRFWW', 'KKXR', 'KKXRF', 'KKXRFW', 'KKXRFWW', 'KKXRFWWW', 'KXRF', 'KXRFW', 'KXRFWW', 'KXRFWWW', 'RFWW', 'RFWWW', 'FWWW', 'FWWWXXXK', 'WWWXXXKK']\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.4 : ['MKKXR', 'MKKXRF', 'MKKXRFW', 'MKKXRFWW', 'KKXR', 'KKXRF', 'KKXRFW', 'KKXRFWW', 'KXRF', 'KXRFW', 'KXRFWW', 'RFWW']\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.5 : ['MKKXXF', 'MKKXXFW', 'MKKXXFWW', 'KKXXFW', 'KKXXFWW', 'KXXFWW']\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.6 : []\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.7 : []\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.8 : []\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 0.9 : []\n",
      "4.2\n",
      "MKKARFWWWVAWKKLLRKKA 1.0 : []\n",
      "4.2\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "file_name = '/home/user2/pj/AMP_2/attention_model/test_motif/score/seq_score_9_7_reg.json'\n",
    "with open(file_name, \"r\") as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "\n",
    "opt_seqls = [\n",
    "\n",
    "'LWWRKAKWKRKIAKRMIRVIGAAKI',                                                                                                                            \n",
    "'KWLGAFGKMRKIAIRLRLKRKKAF',                                                                                                                             \n",
    "'WWRLWKTLLKAPKKLTGLRRW',                                                                                                                             \n",
    "'RKLKKLRWRAGMMYKYVKLK',\n",
    "'MRFPWKHWWKKWKWWWKKKR',\n",
    "'MKKARFWWWVAWKKLLRKKA'\n",
    "]\n",
    "\n",
    "labels = [\n",
    "'myAttention9',\n",
    "'myAttention7',\n",
    "'CNN8',\n",
    "'myAttention9',\n",
    "'myAttention13',\n",
    "'myAttention9'\n",
    "]\n",
    "\n",
    "label_dict = {opt_seqls[i]:labels[i] for i in range(len(opt_seqls))}\n",
    "\n",
    "\n",
    "scoreDict = {}\n",
    "for item in loaded_data:\n",
    "    seq = item['seq']\n",
    "    score = item['score']\n",
    "    scoreDict[seq] = score\n",
    "\n",
    "df_ls = []\n",
    "for seq in opt_seqls:\n",
    "    score = scoreDict[seq]\n",
    "    seq_dict = {'sequence': seq,'model':label_dict[seq]}\n",
    "    for k in range(2,11):\n",
    "        alpha = k/10\n",
    "        ls = find_motif(seq,score,alpha)\n",
    "        print(seq,alpha,':',ls)\n",
    "        print(sum(abs(np.array(grad))))\n",
    "        seq_dict[alpha] = ls\n",
    "    df_ls.append(seq_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    sequence          model  \\\n",
      "0  LWWRKAKWKRKIAKRMIRVIGAAKI   myAttention9   \n",
      "1   KWLGAFGKMRKIAIRLRLKRKKAF   myAttention7   \n",
      "2      WWRLWKTLLKAPKKLTGLRRW           CNN8   \n",
      "3       RKLKKLRWRAGMMYKYVKLK   myAttention9   \n",
      "4       MRFPWKHWWKKWKWWWKKKR  myAttention13   \n",
      "5       MKKARFWWWVAWKKLLRKKA   myAttention9   \n",
      "\n",
      "                                                 0.2  \\\n",
      "0  [LXXRKA, LXXRKAK, LXXRKAKW, RKAK, RKAKW, RKAKW...   \n",
      "1  [KWLG, KWLGA, KWLGAF, KWLGAFG, KWLGAFGK, WLGA,...   \n",
      "2  [WWRL, WWRLW, WWRLWK, WWRLWKT, WWRLWKTL, WRLW,...   \n",
      "3  [RKLK, RKLKK, RKLKKL, RKLKKLR, KLKK, KLKKL, KL...   \n",
      "4  [MRFP, MRFPW, MRFPWK, MRFPWKH, MRFPWKHW, RFPW,...   \n",
      "5  [MKKXR, MKKXRF, MKKXRFW, MKKXRFWW, KKXR, KKXRF...   \n",
      "\n",
      "                                                 0.3  \\\n",
      "0  [KAKXK, KAKXKXK, KAKXKXKI, AKXK, AKXKXK, AKXKX...   \n",
      "1  [KWLG, KWLGA, KWLGAF, KWLGAFG, KWLGAFGK, WLGA,...   \n",
      "2  [WWXL, WWXLW, WWXLWK, WWXLWKT, WWXLWKTL, WXLW,...   \n",
      "3  [RKXK, RKXKK, RKXKKL, RKXKKLR, KXKK, KXKKL, KX...   \n",
      "4  [MRXP, MRXPXK, MRXPXKH, MRXPXKHW, RXPXKH, RXPX...   \n",
      "5  [MKKXR, MKKXRF, MKKXRFW, MKKXRFWW, KKXR, KKXRF...   \n",
      "\n",
      "                                                 0.4  \\\n",
      "0  [KAKXK, KAKXKXK, KAKXKXKI, AKXK, AKXKXK, AKXKX...   \n",
      "1  [KXLG, KXLGA, KXLGAF, KXLGAFG, KXLGAFGK, LGAF,...   \n",
      "2                                             [LXKT]   \n",
      "3  [RKXK, RKXKK, RKXKKL, RKXKKLR, KXKK, KXKKL, KX...   \n",
      "4  [MRXP, MRXPXK, MRXPXKH, MRXPXKHW, RXPXKH, RXPX...   \n",
      "5  [MKKXR, MKKXRF, MKKXRFW, MKKXRFWW, KKXR, KKXRF...   \n",
      "\n",
      "                                                 0.5  \\\n",
      "0  [KAKXK, KAKXKXK, KAKXKXKI, AKXK, AKXKXK, AKXKX...   \n",
      "1  [LGAF, LGAFG, LGAFGK, LGAFGKM, GAFG, GAFGK, GA...   \n",
      "2                                             [LXKT]   \n",
      "3  [RKXK, RKXKK, RKXKKL, RKXKKLR, KXKK, KXKKL, KX...   \n",
      "4  [MRXP, MRXPXK, MRXPXKH, MRXPXKHW, RXPXKH, RXPX...   \n",
      "5  [MKKXXF, MKKXXFW, MKKXXFWW, KKXXFW, KKXXFWW, K...   \n",
      "\n",
      "                                                 0.6  \\\n",
      "0                                     [IXKXMI, KXMI]   \n",
      "1  [LGAF, LGAFG, LGAFGK, LGAFGKM, GAFG, GAFGK, GA...   \n",
      "2                                             [LXKT]   \n",
      "3                 [RKXK, RKXKK, RKXKKL, KXKK, KXKKL]   \n",
      "4  [MRXXXKHW, KHWXK, KHWXKK, KHWXKKXK, HWXK, HWXK...   \n",
      "5                                                 []   \n",
      "\n",
      "                                                 0.7  \\\n",
      "0                                                 []   \n",
      "1  [LGAF, LGAFG, LGAFGK, LGAFGKM, GAFG, GAFGK, GA...   \n",
      "2                                                 []   \n",
      "3                 [RKXK, RKXKK, RKXKKL, KXKK, KXKKL]   \n",
      "4                           [KHXXKK, KHXXKKXK, KKXK]   \n",
      "5                                                 []   \n",
      "\n",
      "                                          0.8                       0.9 1.0  \n",
      "0                                          []                        []  []  \n",
      "1  [LGXF, LGXFG, LGXFGXM, GXFG, GXFGXM, FGXM]                        []  []  \n",
      "2                                          []                        []  []  \n",
      "3          [RKXK, RKXKK, RKXKKL, KXKK, KXKKL]             [KXKK, KXKKL]  []  \n",
      "4                    [KHXXKK, KHXXKKXK, KKXK]  [KHXXKK, KHXXKKXK, KKXK]  []  \n",
      "5                                          []                        []  []  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(df_ls)\n",
    "print(df)\n",
    "df.to_csv('./6peptid_sign_only_threshold_rank_0.2_attention_score.csv',index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1312, 3)\n",
      "\n",
      "myAttention _V2:\n",
      "MKKARFWWWVAWKKLLRKKA\n",
      "{'myAttention': [0.153208447175486, 0.020525608204773126, 0.0013144287048440777, 0.027304417124256988, 0.36332461671415434, 0.048659490991791, 0.09964009626999414, 0.03316174482352915, -0.007934305219482416, -0.02032431014211555, 0.0031446601535416435, 0.017557999498349297, -0.017903503413233348, 0.003018150422452292, 0.0658418824121672, 0.05011999926403741, -0.000879505613447257, 0.016463834797143473, 0.029862093833343734, -0.019810905221857633]}\n",
      "M: 0.153208447175486\n",
      "K: 0.020525608204773126\n",
      "K: 0.0013144287048440777\n",
      "A: 0.027304417124256988\n",
      "R: 0.36332461671415434\n",
      "F: 0.048659490991791\n",
      "W: 0.09964009626999414\n",
      "W: 0.03316174482352915\n",
      "W: -0.007934305219482416\n",
      "V: -0.02032431014211555\n",
      "A: 0.0031446601535416435\n",
      "W: 0.017557999498349297\n",
      "K: -0.017903503413233348\n",
      "K: 0.003018150422452292\n",
      "L: 0.0658418824121672\n",
      "L: 0.05011999926403741\n",
      "R: -0.000879505613447257\n",
      "K: 0.016463834797143473\n",
      "K: 0.029862093833343734\n",
      "A: -0.019810905221857633\n"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    # \n",
    "    'myAttention': '../../NewModel3_21_output1_Regression/myAttention/mean_0_changeTH_0_0/_AMP0.629_total0.543.pth',\n",
    "\n",
    "}\n",
    "\n",
    "test_model_list = model_list\n",
    "\n",
    "opt_seqls = [\n",
    "\n",
    "'MKKARFWWWVAWKKLLRKKA'\n",
    "]\n",
    "\n",
    "labels = [\n",
    "'myAttention9',\n",
    "'myAttention7',\n",
    "'CNN8',\n",
    "'myAttention9',\n",
    "'myAttention13',\n",
    "'myAttention9'\n",
    "]\n",
    "\n",
    "label_dict = {opt_seqls[i]:labels[i] for i in range(len(opt_seqls))}\n",
    "\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# 指定之前保存的 JSON 文件名\n",
    "file_name = \"/home/user2/pj/AMP_2/attention_model/test_motif/score/seq_score_9_7_reg.json\"\n",
    "\n",
    "\n",
    "with open(file_name, \"r\") as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "score_seq_dict = {}\n",
    "for item in loaded_data:\n",
    "    seq = item['seq']\n",
    "    # print(seq)\n",
    "    score = np.array(item['score'])\n",
    "    score_seq_dict[seq] = score\n",
    "    # print(score.shape)\n",
    "    # draw_weight2(score,seq,'layer1')\n",
    "\n",
    "\n",
    "df_ls = []\n",
    "from matplotlib.colors import Normalize\n",
    "norm = Normalize(vmin=-0.2, vmax=0.2)\n",
    "for seq in opt_seqls:\n",
    "    tseq = seq\n",
    "\n",
    "    # ModelNameList = ['CNN','Transformer','myAttention','RCNN']\n",
    "    ModelNameList = model_list.keys()\n",
    "\n",
    "    gradient = {}\n",
    "    \n",
    "\n",
    "    oriseq = tseq\n",
    "\n",
    "    # 在当前目录生成 该序列的csv 文件\n",
    "    df = pd.DataFrame(columns = ['Sequence','Length','label'])\n",
    "    items = [{'Sequence':oriseq,'Length':len(oriseq)}]\n",
    "    df = df.append(items,ignore_index = 1)\n",
    "    df.to_csv(oriseq+'.csv',index = False)\n",
    "\n",
    "\n",
    "    SeqPath = oriseq+'.csv'\n",
    "\n",
    "\n",
    "\n",
    "    testData1 = TrainDataset(data_path = r'../../myRegressionData/all_balance/mean/test.csv')\n",
    "    test_loader1 = DataLoader(dataset=testData1, batch_size=4,drop_last=True)\n",
    "\n",
    "\n",
    "    for modelName in ModelNameList:\n",
    "\n",
    "        # modelName = 'myAttention'  # to change\n",
    "        iternum = 0\n",
    "\n",
    "        testData = TestDataset(data_path = SeqPath)\n",
    "        test_loader = DataLoader(dataset=testData, batch_size=1)\n",
    "        attmodel = torch.load(model_list[modelName])\n",
    "\n",
    "\n",
    "        attmodel.cuda()\n",
    "        attmodel.zero_grad()\n",
    "\n",
    "        print(modelName,\"_V2:\")\n",
    "\n",
    "            \n",
    "        for data in test_loader: #序列优化 stratergy 1: 全局都用ensamble作为优化目标\n",
    "            resultList = []\n",
    "            # ensamble_values = []\n",
    "            resultSeq = [oriseq]\n",
    "            outMIC = []\n",
    "            # attmodel.zero_grad()\n",
    "            inputs,masks, seqs = data\n",
    "\n",
    "            inputs = inputs.float()\n",
    "            masks = masks.float()\n",
    "            \n",
    "            # inputs = inputs.cuda()\n",
    "            # inputs.requires_grad = True\n",
    "            masks = masks.cuda()\n",
    "            print(seqs[0])\n",
    "\n",
    "            if modelName == 'RCNN':\n",
    "                attmodel.train()\n",
    "            else:\n",
    "                attmodel.eval()\n",
    "    \n",
    "            attmodel.zero_grad()\n",
    "            stdev_spread = 0.1\n",
    "            n_samples = 25\n",
    "            x = inputs[0].detach()\n",
    "            stdev = stdev_spread * (torch.max(x)-torch.min(x))\n",
    "            x = x.numpy() \n",
    "            total_grad = np.zeros_like(x)\n",
    "            for i in range(n_samples):\n",
    "\n",
    "                    # final.append(xx)\n",
    "                noise = np.random.normal(0,stdev,x.shape).astype(np.float32)\n",
    "                x_plus_noise = x + noise\n",
    "                \n",
    "                x_plus_noise = torch.from_numpy(x_plus_noise).cuda()\n",
    "                # x_plus_noise = x_plus_noise + 0.1\n",
    "                x_plus_noise[masks[0]==1] = 0\n",
    "                x_plus_noise = Variable(torch.unsqueeze(x_plus_noise,dim=0), requires_grad = True)\n",
    "                # final.append(x_plus_noise)\n",
    "                if i==0:\n",
    "                    x_plus_noise = Variable(inputs.cuda(), requires_grad = True)\n",
    "            \n",
    "                if modelName == 'lstm_att' or modelName == 'RCNN'or modelName == 'CNN' or modelName == 'Transformer':\n",
    "                    out = attmodel(x_plus_noise)\n",
    "                else:\n",
    "                    out = attmodel(x_plus_noise,masks)\n",
    "\n",
    "                out = out.cpu()\n",
    "                if 'RCNN' in modelName:\n",
    "                    out = out.unsqueeze(0)\n",
    "\n",
    "                conloss = -out\n",
    "\n",
    "                conloss.backward()\n",
    "                grad = x_plus_noise.grad\n",
    "                # if i==0:\n",
    "                #     print(grad)\n",
    "                colindex = masks[0]==1\n",
    "                grad[0][masks[0]==1] = 0\n",
    "                grad = grad[0].cpu().numpy()\n",
    "                \n",
    "                total_grad += grad\n",
    "\n",
    "\n",
    "            avg_grad = total_grad/n_samples\n",
    "            myIndex = [mydict[v] for v in seqs[0]]\n",
    "\n",
    "            mylen = 100-colindex.sum()\n",
    "            # print(mylen)\n",
    "            grad = avg_grad[:mylen]\n",
    "            # grad = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            mag = np.sum(abs(grad),axis=-1).tolist()\n",
    "\n",
    "            # print(np.sum(grad))\n",
    "\n",
    "            value = [grad[k,myIndex[k]] for k in range(len(seqs[0]))]\n",
    "            # print(value)\n",
    "            # max_grad = np.max(grad,axis=-1).tolist()\n",
    "            # # grad  =  [value[i]/max_grad[i] for i in range(len(grad))]\n",
    "            grad = [mag[k]*value[k] for k in range(len(value))]\n",
    "            # grad = list(np.exp(grad))\n",
    "\n",
    "            absGrad = np.sum(abs(np.array(grad)))\n",
    "            grad = [v/absGrad for v in grad]\n",
    "            # grad = [ v/sum(grad) for v in grad]\n",
    "            gradient[modelName] = grad\n",
    "    seq_dict = {'sequence': seq,'model':label_dict[seq]}\n",
    "    print(gradient)\n",
    "    for k, v in gradient.items():\n",
    "        for id in range(len(seq)):\n",
    "            print(str(seq[id])+\":\",v[id])\n",
    "    # for k in range(11):\n",
    "    #     alpha = k/100\n",
    "    #     ls = find_motif(tseq,grad,alpha)\n",
    "    #     print(tseq,':',ls)\n",
    "    #     print(sum(abs(np.array(grad))))\n",
    "    #     seq_dict[alpha] = ls\n",
    "\n",
    "    # df_ls.append(seq_dict)\n",
    "\n",
    "\n",
    "    # print(gradient)\n",
    "    # grad = gradient['myAttention']\n",
    "    # alpha = 0.05\n",
    "    # ls = find_motif(tseq,grad,alpha)\n",
    "    # print(tseq,':',ls)\n",
    "    # print(sum(abs(np.array(grad))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
